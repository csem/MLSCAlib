%% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}


\PassOptionsToPackage{warn}{textcomp}
\usepackage[utf8]{inputenc}
\ifdefined\DeclareUnicodeCharacter
% support both utf8 and utf8x syntaxes
  \ifdefined\DeclareUnicodeCharacterAsOptional
    \def\sphinxDUC#1{\DeclareUnicodeCharacter{"#1}}
  \else
    \let\sphinxDUC\DeclareUnicodeCharacter
  \fi
  \sphinxDUC{00A0}{\nobreakspace}
  \sphinxDUC{2500}{\sphinxunichar{2500}}
  \sphinxDUC{2502}{\sphinxunichar{2502}}
  \sphinxDUC{2514}{\sphinxunichar{2514}}
  \sphinxDUC{251C}{\sphinxunichar{251C}}
  \sphinxDUC{2572}{\textbackslash}
\fi
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb,amstext}
\usepackage{babel}



\usepackage{tgtermes}
\usepackage{tgheros}
\renewcommand{\ttdefault}{txtt}



\usepackage[Bjarne]{fncychap}
\usepackage{sphinx}

\fvset{fontsize=auto}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}

\addto\captionsenglish{\renewcommand{\contentsname}{Contents:}}

\usepackage{sphinxmessages}
\setcounter{tocdepth}{1}



\title{MLSCAlib}
\date{Mar 29, 2023}
\release{v0.2}
\author{Anonymous Submission}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{Release}
\makeindex
\begin{document}

\ifdefined\shorthandoff
  \ifnum\catcode`\=\string=\active\shorthandoff{=}\fi
  \ifnum\catcode`\"=\active\shorthandoff{"}\fi
\fi

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{index::doc}}


\sphinxstepscope


\chapter{MLSCAlib}
\label{\detokenize{modules:mlscalib}}\label{\detokenize{modules::doc}}
\sphinxstepscope


\section{MLSCAlib package}
\label{\detokenize{MLSCAlib:mlscalib-package}}\label{\detokenize{MLSCAlib::doc}}

\subsection{Subpackages}
\label{\detokenize{MLSCAlib:subpackages}}
\sphinxstepscope


\subsubsection{MLSCAlib.Architectures package}
\label{\detokenize{MLSCAlib.Architectures:mlscalib-architectures-package}}\label{\detokenize{MLSCAlib.Architectures::doc}}

\paragraph{Submodules}
\label{\detokenize{MLSCAlib.Architectures:submodules}}

\paragraph{MLSCAlib.Architectures.autoencoders module}
\label{\detokenize{MLSCAlib.Architectures:module-MLSCAlib.Architectures.autoencoders}}\label{\detokenize{MLSCAlib.Architectures:mlscalib-architectures-autoencoders-module}}\index{module@\spxentry{module}!MLSCAlib.Architectures.autoencoders@\spxentry{MLSCAlib.Architectures.autoencoders}}\index{MLSCAlib.Architectures.autoencoders@\spxentry{MLSCAlib.Architectures.autoencoders}!module@\spxentry{module}}\index{old\_cnn() (in module MLSCAlib.Architectures.autoencoders)@\spxentry{old\_cnn()}\spxextra{in module MLSCAlib.Architectures.autoencoders}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.autoencoders.old_cnn}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{MLSCAlib.Architectures.autoencoders.}}\sphinxbfcode{\sphinxupquote{old\_cnn}}}{\emph{\DUrole{n}{lr}}, \emph{\DUrole{n}{input\_length}}}{}
\pysigstopsignatures
\sphinxAtStartPar
old\_cnn : autoencoder architecture from Wu and Picek%
\begin{footnote}[1]\sphinxAtStartFootnote
Lichao Wu and Stjepan Picek. Remove some noise: on pre\sphinxhyphen{}processing of side\sphinxhyphen{}channel measurements with autoencoders. \sphinxstyleemphasis{IACR Transactions on Cryptographic Hardware and Embedded Systems}, pages 389\textendash{}415, 2020.
%
\end{footnote}.

\sphinxAtStartPar
The input length must have been padded to a multiple of 20.

\end{fulllineitems}



\paragraph{MLSCAlib.Architectures.torch\_models module}
\label{\detokenize{MLSCAlib.Architectures:module-MLSCAlib.Architectures.torch_models}}\label{\detokenize{MLSCAlib.Architectures:mlscalib-architectures-torch-models-module}}\index{module@\spxentry{module}!MLSCAlib.Architectures.torch\_models@\spxentry{MLSCAlib.Architectures.torch\_models}}\index{MLSCAlib.Architectures.torch\_models@\spxentry{MLSCAlib.Architectures.torch\_models}!module@\spxentry{module}}\index{AgnosticModel (class in MLSCAlib.Architectures.torch\_models)@\spxentry{AgnosticModel}\spxextra{class in MLSCAlib.Architectures.torch\_models}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.AgnosticModel}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Architectures.torch\_models.}}\sphinxbfcode{\sphinxupquote{AgnosticModel}}}{\emph{\DUrole{n}{num\_classes}}, \emph{\DUrole{n}{ns}}, \emph{\DUrole{n}{dk}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{noise\_std}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{dim}\DUrole{o}{=}\DUrole{default_value}{0}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}
\index{forward() (MLSCAlib.Architectures.torch\_models.AgnosticModel method)@\spxentry{forward()}\spxextra{MLSCAlib.Architectures.torch\_models.AgnosticModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.AgnosticModel.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{class\_ixes}\DUrole{o}{=}\DUrole{default_value}{{[}{]}}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Defines the computation performed at every call.

\sphinxAtStartPar
Should be overridden by all subclasses.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Although the recipe for forward pass needs to be defined within
this function, one should call the \sphinxcode{\sphinxupquote{Module}} instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.
\end{sphinxadmonition}

\end{fulllineitems}

\index{set\_dim() (MLSCAlib.Architectures.torch\_models.AgnosticModel method)@\spxentry{set\_dim()}\spxextra{MLSCAlib.Architectures.torch\_models.AgnosticModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.AgnosticModel.set_dim}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_dim}}}{\emph{\DUrole{n}{dim}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{training (MLSCAlib.Architectures.torch\_models.AgnosticModel attribute)@\spxentry{training}\spxextra{MLSCAlib.Architectures.torch\_models.AgnosticModel attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.AgnosticModel.training}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{training}}\sphinxbfcode{\sphinxupquote{\DUrole{p}{:}\DUrole{w}{  }bool}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{CNN\_MPP16 (class in MLSCAlib.Architectures.torch\_models)@\spxentry{CNN\_MPP16}\spxextra{class in MLSCAlib.Architectures.torch\_models}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.CNN_MPP16}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Architectures.torch\_models.}}\sphinxbfcode{\sphinxupquote{CNN\_MPP16}}}{\emph{\DUrole{n}{num\_classes}}, \emph{\DUrole{n}{ns}}, \emph{\DUrole{n}{dk}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{noise\_std}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{dim}\DUrole{o}{=}\DUrole{default_value}{0}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
CNN\_MPP16: neural network proposed in Maghrebi \sphinxstyleemphasis{et al.}%
\begin{footnote}[2]\sphinxAtStartFootnote
Houssem Maghrebi, Thibault Portigliatti, and Emmanuel Prouff. Breaking cryptographic implementations using deep learning techniques. 12 2016. \sphinxhref{https://doi.org/10.1007/978-3-319-49445-6\_1}{doi:10.1007/978\sphinxhyphen{}3\sphinxhyphen{}319\sphinxhyphen{}49445\sphinxhyphen{}6\_1}.
%
\end{footnote} to break ASCAD, with or without desyncronization techniques.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num\_classes}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of classes, depending on the leakage model.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ns}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of samples per trace.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{DK}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to use Domain Knowledge neurons or not.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{noise\_std}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} Standard deviation of the gaussian noise to add to the training traces. If set
to None, won’t add this noise.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dim}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1}}) \textendash{} If set to 0, computes the output probas on the batch. If set to 1, computes proba on
each sample separately.

\end{itemize}

\end{description}\end{quote}
\index{forward() (MLSCAlib.Architectures.torch\_models.CNN\_MPP16 method)@\spxentry{forward()}\spxextra{MLSCAlib.Architectures.torch\_models.CNN\_MPP16 method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.CNN_MPP16.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\emph{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Defines the computation performed at every call.

\sphinxAtStartPar
Should be overridden by all subclasses.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Although the recipe for forward pass needs to be defined within
this function, one should call the \sphinxcode{\sphinxupquote{Module}} instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.
\end{sphinxadmonition}

\end{fulllineitems}

\index{set\_dim() (MLSCAlib.Architectures.torch\_models.CNN\_MPP16 method)@\spxentry{set\_dim()}\spxextra{MLSCAlib.Architectures.torch\_models.CNN\_MPP16 method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.CNN_MPP16.set_dim}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_dim}}}{\emph{\DUrole{n}{dim}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{training (MLSCAlib.Architectures.torch\_models.CNN\_MPP16 attribute)@\spxentry{training}\spxextra{MLSCAlib.Architectures.torch\_models.CNN\_MPP16 attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.CNN_MPP16.training}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{training}}\sphinxbfcode{\sphinxupquote{\DUrole{p}{:}\DUrole{w}{  }bool}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{CNNexp (class in MLSCAlib.Architectures.torch\_models)@\spxentry{CNNexp}\spxextra{class in MLSCAlib.Architectures.torch\_models}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.CNNexp}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Architectures.torch\_models.}}\sphinxbfcode{\sphinxupquote{CNNexp}}}{\emph{\DUrole{n}{num\_classes}}, \emph{\DUrole{n}{ns}}, \emph{\DUrole{n}{dk}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{noise\_std}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{dim}\DUrole{o}{=}\DUrole{default_value}{0}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
CNNExp: neural network proposed in Timon%
\begin{footnote}[3]\sphinxAtStartFootnote
Benjamin Timon. Non\sphinxhyphen{}profiled deep learning\sphinxhyphen{}based side\sphinxhyphen{}channel attacks with sensitivity analysis. \sphinxstyleemphasis{IACR Transactions on Cryptographic Hardware and Embedded Systems}, 2019(2):107\textendash{}131, February 2019. URL: \sphinxurl{https://tches.iacr.org/index.php/TCHES/article/view/7387}, \sphinxhref{https://doi.org/10.13154/tches.v2019.i2.107-131}{doi:10.13154/tches.v2019.i2.107\sphinxhyphen{}131}.
%
\end{footnote} to break ASCAD, with or without desyncronization techniques.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num\_classes}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of classes, depending on the leakage model.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ns}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of samples per trace.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{DK}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to use Domain Knowledge neurons or not.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{noise\_std}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} Standard deviation of the gaussian noise to add to the training traces. If set
to None, won’t add this noise.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dim}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1}}) \textendash{} If set to 0, computes the output probas on the batch. If set to 1, computes proba on
each sample separately.

\end{itemize}

\end{description}\end{quote}
\index{forward() (MLSCAlib.Architectures.torch\_models.CNNexp method)@\spxentry{forward()}\spxextra{MLSCAlib.Architectures.torch\_models.CNNexp method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.CNNexp.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\emph{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Defines the computation performed at every call.

\sphinxAtStartPar
Should be overridden by all subclasses.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Although the recipe for forward pass needs to be defined within
this function, one should call the \sphinxcode{\sphinxupquote{Module}} instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.
\end{sphinxadmonition}

\end{fulllineitems}

\index{set\_dim() (MLSCAlib.Architectures.torch\_models.CNNexp method)@\spxentry{set\_dim()}\spxextra{MLSCAlib.Architectures.torch\_models.CNNexp method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.CNNexp.set_dim}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_dim}}}{\emph{\DUrole{n}{dim}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{training (MLSCAlib.Architectures.torch\_models.CNNexp attribute)@\spxentry{training}\spxextra{MLSCAlib.Architectures.torch\_models.CNNexp attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.CNNexp.training}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{training}}\sphinxbfcode{\sphinxupquote{\DUrole{p}{:}\DUrole{w}{  }bool}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{MCNN (class in MLSCAlib.Architectures.torch\_models)@\spxentry{MCNN}\spxextra{class in MLSCAlib.Architectures.torch\_models}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MCNN}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Architectures.torch\_models.}}\sphinxbfcode{\sphinxupquote{MCNN}}}{\emph{\DUrole{n}{num\_classes}}, \emph{\DUrole{n}{ns}}, \emph{\DUrole{n}{dk}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{noise\_std}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{dim}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{third\_processing}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}PCA\textquotesingle{}}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
MCNN: multi\sphinxhyphen{}scale convolutional neural networks (MCNN).
\begin{quote}

\sphinxAtStartPar
Inspired from \sphinxurl{https://github.com/mitMathe/SCA-MCNN}.
\end{quote}

\sphinxAtStartPar
Model inspired from Won \sphinxstyleemphasis{et al.}%
\begin{footnote}[4]\sphinxAtStartFootnote
Yoo\sphinxhyphen{}Seung Won, Xiaolu Hou, Dirmanto Jap, Jakub Breier, and Shivam Bhasin. Back to the basics: seamless integration of side\sphinxhyphen{}channel pre\sphinxhyphen{}processing in deep neural networks. \sphinxstyleemphasis{IEEE Transactions on Information Forensics and Security}, 16():3215\textendash{}3227, 2021. \sphinxhref{https://doi.org/10.1109/TIFS.2021.3076928}{doi:10.1109/TIFS.2021.3076928}.
%
\end{footnote} and Won \sphinxstyleemphasis{et al.}%
\begin{footnote}[5]\sphinxAtStartFootnote
Yoo\sphinxhyphen{}Seung Won, Xiaolu Hou, Dirmanto Jap, Jakub Breier, and Shivam Bhasin. Multi\sphinxhyphen{}scale convolutional neural networks (mcnn) based side\sphinxhyphen{}channel analysis. \sphinxurl{https://github.com/mitMathe/SCA-MCNN}, 2021.
%
\end{footnote}.
Includes preprocessing steps inside the architecture. Should be working well on any kind of implementation.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num\_classes}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of classes, depending on the leakage model.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ns}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of samples per trace.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{DK}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to use Domain Knowledge neurons or not.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{noise\_std}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} Standard deviation of the gaussian noise to add to the training traces. If set
to None, won’t add this noise.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dim}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1}}) \textendash{} If set to 0, computes the output probas on the batch. If set to 1, computes proba on
each sample separately.

\end{itemize}

\end{description}\end{quote}
\index{forward() (MLSCAlib.Architectures.torch\_models.MCNN method)@\spxentry{forward()}\spxextra{MLSCAlib.Architectures.torch\_models.MCNN method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MCNN.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\emph{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Defines the computation performed at every call.

\sphinxAtStartPar
Should be overridden by all subclasses.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Although the recipe for forward pass needs to be defined within
this function, one should call the \sphinxcode{\sphinxupquote{Module}} instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.
\end{sphinxadmonition}

\end{fulllineitems}

\index{set\_dim() (MLSCAlib.Architectures.torch\_models.MCNN method)@\spxentry{set\_dim()}\spxextra{MLSCAlib.Architectures.torch\_models.MCNN method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MCNN.set_dim}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_dim}}}{\emph{\DUrole{n}{dim}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{training (MLSCAlib.Architectures.torch\_models.MCNN attribute)@\spxentry{training}\spxextra{MLSCAlib.Architectures.torch\_models.MCNN attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MCNN.training}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{training}}\sphinxbfcode{\sphinxupquote{\DUrole{p}{:}\DUrole{w}{  }bool}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{MLP (class in MLSCAlib.Architectures.torch\_models)@\spxentry{MLP}\spxextra{class in MLSCAlib.Architectures.torch\_models}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MLP}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Architectures.torch\_models.}}\sphinxbfcode{\sphinxupquote{MLP}}}{\emph{\DUrole{n}{num\_classes}}, \emph{\DUrole{n}{ns}}, \emph{\DUrole{n}{dk}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{noise\_std}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{dim}\DUrole{o}{=}\DUrole{default_value}{0}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
MLP: MLP architecture as proposed in Timon\sphinxfootnotemark[3], and used in Kuroda \sphinxstyleemphasis{et al.}%
\begin{footnote}[6]\sphinxAtStartFootnote
Kunihiro Kuroda, Yuta Fukuda, Kota Yoshida, and Takeshi Fujino. Practical aspects on non\sphinxhyphen{}profiled deep\sphinxhyphen{}learning side\sphinxhyphen{}channel attacks against aes software implementation with two types of masking countermeasures including rsm. In \sphinxstyleemphasis{Proceedings of the 5th Workshop on Attacks and Solutions in Hardware Security}, ASHES ‘21, 29\textendash{}40. New York, NY, USA, 2021. Association for Computing Machinery. URL: \sphinxurl{https://doi.org/10.1145/3474376.3487285}, \sphinxhref{https://doi.org/10.1145/3474376.3487285}{doi:10.1145/3474376.3487285}.
%
\end{footnote}, to break unprotected AES.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num\_classes}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of classes, depending on the leakage model.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ns}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of samples per trace.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{DK}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to use Domain Knowledge neurons or not.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{noise\_std}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} Standard deviation of the gaussian noise to add to the training traces. If set
to None, won’t add this noise.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dim}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1}}) \textendash{} If set to 0, computes the output probas on the batch. If set to 1, computes proba on
each sample separately.

\end{itemize}

\end{description}\end{quote}
\index{forward() (MLSCAlib.Architectures.torch\_models.MLP method)@\spxentry{forward()}\spxextra{MLSCAlib.Architectures.torch\_models.MLP method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MLP.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\emph{\DUrole{n}{x}}, \emph{\DUrole{n}{classes}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Defines the computation performed at every call.

\sphinxAtStartPar
Should be overridden by all subclasses.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Although the recipe for forward pass needs to be defined within
this function, one should call the \sphinxcode{\sphinxupquote{Module}} instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.
\end{sphinxadmonition}

\end{fulllineitems}

\index{set\_dim() (MLSCAlib.Architectures.torch\_models.MLP method)@\spxentry{set\_dim()}\spxextra{MLSCAlib.Architectures.torch\_models.MLP method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MLP.set_dim}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_dim}}}{\emph{\DUrole{n}{dim}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{training (MLSCAlib.Architectures.torch\_models.MLP attribute)@\spxentry{training}\spxextra{MLSCAlib.Architectures.torch\_models.MLP attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MLP.training}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{training}}\sphinxbfcode{\sphinxupquote{\DUrole{p}{:}\DUrole{w}{  }bool}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{MLP\_AESRD (class in MLSCAlib.Architectures.torch\_models)@\spxentry{MLP\_AESRD}\spxextra{class in MLSCAlib.Architectures.torch\_models}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MLP_AESRD}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Architectures.torch\_models.}}\sphinxbfcode{\sphinxupquote{MLP\_AESRD}}}{\emph{\DUrole{n}{num\_classes}}, \emph{\DUrole{n}{ns}}, \emph{\DUrole{n}{dk}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{noise\_std}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{dim}\DUrole{o}{=}\DUrole{default_value}{0}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
MLP\_AESRD: MLP architecture as proposed in Weissbart%
\begin{footnote}[7]\sphinxAtStartFootnote
Léo Weissbart. Performance analysis of multilayer perceptron in profiling side\sphinxhyphen{}channel analysis. In \sphinxstyleemphasis{Lecture Notes in Computer Science}, pages 198\textendash{}216. Springer International Publishing, 2020. URL: \sphinxurl{https://doi.org/10.1007/978-3-030-61638-0\_12}, \sphinxhref{https://doi.org/10.1007/978-3-030-61638-0\_12}{doi:10.1007/978\sphinxhyphen{}3\sphinxhyphen{}030\sphinxhyphen{}61638\sphinxhyphen{}0\_12}.
%
\end{footnote} to break the AES\_RD dataset.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num\_classes}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of classes, depending on the leakage model.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ns}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of samples per trace.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{DK}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to use Domain Knowledge neurons or not.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{noise\_std}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} Standard deviation of the gaussian noise to add to the training traces. If set
to None, won’t add this noise.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dim}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1}}) \textendash{} If set to 0, computes the output probas on the batch. If set to 1, computes proba on
each sample separately.

\end{itemize}

\end{description}\end{quote}
\index{forward() (MLSCAlib.Architectures.torch\_models.MLP\_AESRD method)@\spxentry{forward()}\spxextra{MLSCAlib.Architectures.torch\_models.MLP\_AESRD method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MLP_AESRD.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\emph{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Defines the computation performed at every call.

\sphinxAtStartPar
Should be overridden by all subclasses.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Although the recipe for forward pass needs to be defined within
this function, one should call the \sphinxcode{\sphinxupquote{Module}} instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.
\end{sphinxadmonition}

\end{fulllineitems}

\index{set\_dim() (MLSCAlib.Architectures.torch\_models.MLP\_AESRD method)@\spxentry{set\_dim()}\spxextra{MLSCAlib.Architectures.torch\_models.MLP\_AESRD method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MLP_AESRD.set_dim}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_dim}}}{\emph{\DUrole{n}{dim}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{training (MLSCAlib.Architectures.torch\_models.MLP\_AESRD attribute)@\spxentry{training}\spxextra{MLSCAlib.Architectures.torch\_models.MLP\_AESRD attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MLP_AESRD.training}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{training}}\sphinxbfcode{\sphinxupquote{\DUrole{p}{:}\DUrole{w}{  }bool}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{MLP\_ASCAD (class in MLSCAlib.Architectures.torch\_models)@\spxentry{MLP\_ASCAD}\spxextra{class in MLSCAlib.Architectures.torch\_models}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MLP_ASCAD}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Architectures.torch\_models.}}\sphinxbfcode{\sphinxupquote{MLP\_ASCAD}}}{\emph{\DUrole{n}{num\_classes}}, \emph{\DUrole{n}{ns}}, \emph{\DUrole{n}{dk}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{noise\_std}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{dim}\DUrole{o}{=}\DUrole{default_value}{0}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
MLP\_ASCAD: MLP architecture as proposed in Weissbart\sphinxfootnotemark[7] to break ASCAD.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num\_classes}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of classes, depending on the leakage model.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ns}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of samples per trace.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{DK}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to use Domain Knowledge neurons or not.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{noise\_std}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} Standard deviation of the gaussian noise to add to the training traces. If set
to None, won’t add this noise.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dim}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1}}) \textendash{} If set to 0, computes the output probas on the batch. If set to 1, computes proba on
each sample separately.

\end{itemize}

\end{description}\end{quote}
\index{forward() (MLSCAlib.Architectures.torch\_models.MLP\_ASCAD method)@\spxentry{forward()}\spxextra{MLSCAlib.Architectures.torch\_models.MLP\_ASCAD method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MLP_ASCAD.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\emph{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Defines the computation performed at every call.

\sphinxAtStartPar
Should be overridden by all subclasses.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Although the recipe for forward pass needs to be defined within
this function, one should call the \sphinxcode{\sphinxupquote{Module}} instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.
\end{sphinxadmonition}

\end{fulllineitems}

\index{set\_dim() (MLSCAlib.Architectures.torch\_models.MLP\_ASCAD method)@\spxentry{set\_dim()}\spxextra{MLSCAlib.Architectures.torch\_models.MLP\_ASCAD method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MLP_ASCAD.set_dim}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_dim}}}{\emph{\DUrole{n}{dim}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{training (MLSCAlib.Architectures.torch\_models.MLP\_ASCAD attribute)@\spxentry{training}\spxextra{MLSCAlib.Architectures.torch\_models.MLP\_ASCAD attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MLP_ASCAD.training}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{training}}\sphinxbfcode{\sphinxupquote{\DUrole{p}{:}\DUrole{w}{  }bool}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{MLPexp (class in MLSCAlib.Architectures.torch\_models)@\spxentry{MLPexp}\spxextra{class in MLSCAlib.Architectures.torch\_models}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MLPexp}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Architectures.torch\_models.}}\sphinxbfcode{\sphinxupquote{MLPexp}}}{\emph{\DUrole{n}{num\_classes}}, \emph{\DUrole{n}{ns}}, \emph{\DUrole{n}{dk}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{noise\_std}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{dim}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{k}\DUrole{o}{=}\DUrole{default_value}{3}}, \emph{\DUrole{n}{stride}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{number\_of\_POI}\DUrole{o}{=}\DUrole{default_value}{5}}, \emph{\DUrole{n}{first\_step}\DUrole{o}{=}\DUrole{default_value}{0.01}}, \emph{\DUrole{n}{next\_steps}\DUrole{o}{=}\DUrole{default_value}{0.1}}, \emph{\DUrole{n}{first\_epoch}\DUrole{o}{=}\DUrole{default_value}{5}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
MLPexp: Experimental MLP.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num\_classes}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of classes, depending on the leakage model.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ns}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of samples per trace.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{DK}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to use Domain Knowledge neurons or not.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{noise\_std}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} Standard deviation of the gaussian noise to add to the training traces. If set
to None, won’t add this noise.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dim}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1}}) \textendash{} If set to 0, computes the output probas on the batch. If set to 1, computes proba on
each sample separately.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{k}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 3}}) \textendash{} Window size. Defines the number of input sample each input neuron will look at
simultaneously.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{stride}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1}}) \textendash{} Stride of input layer. Defines by how much each window is separated. If stride\textgreater{}k, some samples
will be ignored. If stride == k, there is no overlap.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{numer\_of\_POI}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 3}}) \textendash{} How many points of interest (of size k) each trace is supposed to contain. The
input layer will stop pruning until only this number of neurons are activated.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{FIRST\_STEP}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1/100}}) \textendash{} What percentage of remaining nodes to disable at the first removal (at input layer).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{NEXT\_STEPS}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1/10}}) \textendash{} What percentage of remaining nodes to disable at each following epoch (at input layer).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{FIRST\_EPOCH}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 5}}) \textendash{} At which epoch to begin the pruning. If too small, the input layer may
accidentally prune usefull samples.

\end{itemize}

\end{description}\end{quote}
\index{eval() (MLSCAlib.Architectures.torch\_models.MLPexp method)@\spxentry{eval()}\spxextra{MLSCAlib.Architectures.torch\_models.MLPexp method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MLPexp.eval}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{eval}}}{}{}
\pysigstopsignatures
\end{fulllineitems}

\index{forward() (MLSCAlib.Architectures.torch\_models.MLPexp method)@\spxentry{forward()}\spxextra{MLSCAlib.Architectures.torch\_models.MLPexp method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MLPexp.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\emph{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Defines the computation performed at every call.

\sphinxAtStartPar
Should be overridden by all subclasses.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Although the recipe for forward pass needs to be defined within
this function, one should call the \sphinxcode{\sphinxupquote{Module}} instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.
\end{sphinxadmonition}

\end{fulllineitems}

\index{set\_dim() (MLSCAlib.Architectures.torch\_models.MLPexp method)@\spxentry{set\_dim()}\spxextra{MLSCAlib.Architectures.torch\_models.MLPexp method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MLPexp.set_dim}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_dim}}}{\emph{\DUrole{n}{dim}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{training (MLSCAlib.Architectures.torch\_models.MLPexp attribute)@\spxentry{training}\spxextra{MLSCAlib.Architectures.torch\_models.MLPexp attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MLPexp.training}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{training}}\sphinxbfcode{\sphinxupquote{\DUrole{p}{:}\DUrole{w}{  }bool}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{MaskingLayer (class in MLSCAlib.Architectures.torch\_models)@\spxentry{MaskingLayer}\spxextra{class in MLSCAlib.Architectures.torch\_models}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MaskingLayer}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Architectures.torch\_models.}}\sphinxbfcode{\sphinxupquote{MaskingLayer}}}{\emph{\DUrole{n}{size\_in}}, \emph{\DUrole{n}{size\_out}}, \emph{\DUrole{n}{k}\DUrole{o}{=}\DUrole{default_value}{3}}, \emph{\DUrole{n}{stride}\DUrole{o}{=}\DUrole{default_value}{3}}, \emph{\DUrole{n}{number\_of\_POI}\DUrole{o}{=}\DUrole{default_value}{3}}, \emph{\DUrole{n}{first\_step}\DUrole{o}{=}\DUrole{default_value}{0.01}}, \emph{\DUrole{n}{next\_steps}\DUrole{o}{=}\DUrole{default_value}{0.1}}, \emph{\DUrole{n}{first\_epoch}\DUrole{o}{=}\DUrole{default_value}{5}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
Custom Linear layer which has self\sphinxhyphen{}regularization techniques.

\sphinxAtStartPar
It has some constants that may have to be tuned.
\index{\_\_init\_\_() (MLSCAlib.Architectures.torch\_models.MaskingLayer method)@\spxentry{\_\_init\_\_()}\spxextra{MLSCAlib.Architectures.torch\_models.MaskingLayer method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MaskingLayer.__init__}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{\emph{\DUrole{n}{size\_in}}, \emph{\DUrole{n}{size\_out}}, \emph{\DUrole{n}{k}\DUrole{o}{=}\DUrole{default_value}{3}}, \emph{\DUrole{n}{stride}\DUrole{o}{=}\DUrole{default_value}{3}}, \emph{\DUrole{n}{number\_of\_POI}\DUrole{o}{=}\DUrole{default_value}{3}}, \emph{\DUrole{n}{first\_step}\DUrole{o}{=}\DUrole{default_value}{0.01}}, \emph{\DUrole{n}{next\_steps}\DUrole{o}{=}\DUrole{default_value}{0.1}}, \emph{\DUrole{n}{first\_epoch}\DUrole{o}{=}\DUrole{default_value}{5}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Init function.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{size\_in}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} How many neurons/samples the previous layer had. Also: input size.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{size\_out}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} How many output connections this model shoudl have. Also: neuron quantity.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{k}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 3}}) \textendash{} Window size. Defines the number of input sample each neuron will look at
simultaneously.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{stride}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 3}}) \textendash{} Stride. Defines by how much each window is separated. If stride\textgreater{}k, some samples
will be ignored. If stride == k, there is no overlap.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{numer\_of\_POI}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 3}}) \textendash{} How many points of interest (of size k) each trace is supposed to contain. The
MaskingLayer will stop pruning until only this number of neurons are activated.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{FIRST\_STEP}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1/100}}) \textendash{} What percentage of remaining nodes to disable at the first removal.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{NEXT\_STEPS}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1/10}}) \textendash{} What percentage of remaining nodes to disable at each following epoch.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{FIRST\_EPOCH}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 5}}) \textendash{} At which epoch to begin the pruning. If too small, the network may
accidentally prune usefull samples.

\end{itemize}

\sphinxlineitem{Raises}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{AssertionError}} \textendash{} When size\_out != 1 + int((size\_in \sphinxhyphen{} k)/ stride)

\end{description}\end{quote}

\end{fulllineitems}

\index{forward() (MLSCAlib.Architectures.torch\_models.MaskingLayer method)@\spxentry{forward()}\spxextra{MLSCAlib.Architectures.torch\_models.MaskingLayer method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MaskingLayer.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\emph{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Defines the computation performed at every call.

\sphinxAtStartPar
Should be overridden by all subclasses.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Although the recipe for forward pass needs to be defined within
this function, one should call the \sphinxcode{\sphinxupquote{Module}} instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.
\end{sphinxadmonition}

\end{fulllineitems}

\index{train() (MLSCAlib.Architectures.torch\_models.MaskingLayer method)@\spxentry{train()}\spxextra{MLSCAlib.Architectures.torch\_models.MaskingLayer method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MaskingLayer.train}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{train}}}{\emph{\DUrole{n}{bool\_}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Sets the module in training mode.

\sphinxAtStartPar
This has any effect only on certain modules. See documentations of
particular modules for details of their behaviors in training/evaluation
mode, if they are affected, e.g. \sphinxcode{\sphinxupquote{Dropout}}, \sphinxcode{\sphinxupquote{BatchNorm}},
etc.
\begin{description}
\sphinxlineitem{Args:}\begin{description}
\sphinxlineitem{mode (bool): whether to set training mode (\sphinxcode{\sphinxupquote{True}}) or evaluation}
\sphinxAtStartPar
mode (\sphinxcode{\sphinxupquote{False}}). Default: \sphinxcode{\sphinxupquote{True}}.

\end{description}

\sphinxlineitem{Returns:}
\sphinxAtStartPar
Module: self

\end{description}

\end{fulllineitems}

\index{training (MLSCAlib.Architectures.torch\_models.MaskingLayer attribute)@\spxentry{training}\spxextra{MLSCAlib.Architectures.torch\_models.MaskingLayer attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MaskingLayer.training}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{training}}\sphinxbfcode{\sphinxupquote{\DUrole{p}{:}\DUrole{w}{  }bool}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{MeshNN (class in MLSCAlib.Architectures.torch\_models)@\spxentry{MeshNN}\spxextra{class in MLSCAlib.Architectures.torch\_models}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MeshNN}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Architectures.torch\_models.}}\sphinxbfcode{\sphinxupquote{MeshNN}}}{\emph{\DUrole{n}{num\_classes}}, \emph{\DUrole{n}{ns}}, \emph{\DUrole{n}{dk}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{noise\_std}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{dim}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{batch\_size}\DUrole{o}{=}\DUrole{default_value}{100}}, \emph{\DUrole{n}{first\_model}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}cnn\_exp\textquotesingle{}}}, \emph{\DUrole{n}{num\_neurons\_middle}\DUrole{o}{=}\DUrole{default_value}{10}}, \emph{\DUrole{n}{first\_bottleneck\_size\_per\_class}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{second\_bottleneck\_size\_per\_class}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{first\_activation}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}selu\textquotesingle{}}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
Mesh Neural Network.

\sphinxAtStartPar
This network allows for a fine\sphinxhyphen{}tuning of two bottlenecks present in Meshv1.
The first one being at output of the first\_model. Previously, each class
was represented by only one neuron. This can now be increased. Next, the
inner\sphinxhyphen{}MLP could only use 2 neurons as input (remember: one that will only
look at the target trace’s respective class neuron weight output and another
which looks at every trace the respective class neuron weight output). We can
now also increase this bottleneck. Hence, the MeshNN4 is the same as the
MeshNN if the two bottleneck sizes are set to 1.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num\_classes}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of classes, depending on the leakage model.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ns}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of samples per trace.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{DK}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to use Domain Knowledge neurons or not.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{noise\_std}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} Standard deviation of the gaussian noise to add to the training traces. If set
to None, won’t add this noise.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dim}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1}}) \textendash{} If set to 0, computes the output probas on the batch. If set to 1, computes proba on
each sample separately.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{batch\_size}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 100}}) \textendash{} The batch size used for training AND testing.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{first\_model}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{ | }}\sphinxstyleliteralemphasis{\sphinxupquote{torch.nn.Module}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : cnn\_exp}}) \textendash{} The first model to use. You can give an existing (pre\sphinxhyphen{}trained) model, in which case
the function will replace the output logsoftmax of the pretrained model depending
on the first\_activation argument. When given a str as input, it will create a new
trainable model.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num\_neurons\_middle}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 10}}) \textendash{} Number of neurons to put in the hidden layer of the middle MLP.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{first\_bottleneck\_size\_per\_class}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1}}) \textendash{} How many output neurons to assign to each class on the first\_model.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{second\_bottleneck\_size\_per\_class}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1}}) \textendash{} By default, the middle MLP has two input neurons. One containing only the corresponding
trace output probability, and the second combining all of the probabilities over each trace.
The second\_bottleneck\_size\_per\_class allows to increase this bottleneck.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{first\_activation}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : "selu"}}) \textendash{} By what to replace the output softmax ofthe first\_model. Can be “no softmax” (which means, no
activation function at all), “selu”

\end{itemize}

\end{description}\end{quote}
\index{forward() (MLSCAlib.Architectures.torch\_models.MeshNN method)@\spxentry{forward()}\spxextra{MLSCAlib.Architectures.torch\_models.MeshNN method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MeshNN.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\emph{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Defines the computation performed at every call.

\sphinxAtStartPar
Should be overridden by all subclasses.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Although the recipe for forward pass needs to be defined within
this function, one should call the \sphinxcode{\sphinxupquote{Module}} instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.
\end{sphinxadmonition}

\end{fulllineitems}

\index{set\_dim() (MLSCAlib.Architectures.torch\_models.MeshNN method)@\spxentry{set\_dim()}\spxextra{MLSCAlib.Architectures.torch\_models.MeshNN method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MeshNN.set_dim}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_dim}}}{\emph{\DUrole{n}{dim}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{training (MLSCAlib.Architectures.torch\_models.MeshNN attribute)@\spxentry{training}\spxextra{MLSCAlib.Architectures.torch\_models.MeshNN attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.MeshNN.training}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{training}}\sphinxbfcode{\sphinxupquote{\DUrole{p}{:}\DUrole{w}{  }bool}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{NetAeshd (class in MLSCAlib.Architectures.torch\_models)@\spxentry{NetAeshd}\spxextra{class in MLSCAlib.Architectures.torch\_models}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.NetAeshd}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Architectures.torch\_models.}}\sphinxbfcode{\sphinxupquote{NetAeshd}}}{\emph{\DUrole{n}{num\_classes}}, \emph{\DUrole{n}{ns}}, \emph{\DUrole{n}{dk}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{noise\_std}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{dim}\DUrole{o}{=}\DUrole{default_value}{0}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
NetAeshd: neural network proposed in Bossuet and Venelli%
\begin{footnote}[8]\sphinxAtStartFootnote
Zaid Bossuet and Habrard Venelli. Methodology for efficient cnn architectures in profiling attacks. November 2019. URL: \sphinxurl{https://tches.iacr.org/index.php/TCHES/article/view/8391}, \sphinxhref{https://doi.org/10.13154/tches.v2020.i1.1-36}{doi:10.13154/tches.v2020.i1.1\sphinxhyphen{}36}.
%
\end{footnote} to break the AES\_HD dataset, an unprotected AES implementation.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num\_classes}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of classes, depending on the leakage model.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ns}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of samples per trace.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{DK}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to use Domain Knowledge neurons or not.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{noise\_std}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} Standard deviation of the gaussian noise to add to the training traces. If set
to None, won’t add this noise.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dim}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1}}) \textendash{} If set to 0, computes the output probas on the batch. If set to 1, computes proba on
each sample separately.

\end{itemize}

\end{description}\end{quote}
\index{forward() (MLSCAlib.Architectures.torch\_models.NetAeshd method)@\spxentry{forward()}\spxextra{MLSCAlib.Architectures.torch\_models.NetAeshd method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.NetAeshd.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\emph{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Defines the computation performed at every call.

\sphinxAtStartPar
Should be overridden by all subclasses.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Although the recipe for forward pass needs to be defined within
this function, one should call the \sphinxcode{\sphinxupquote{Module}} instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.
\end{sphinxadmonition}

\end{fulllineitems}

\index{set\_dim() (MLSCAlib.Architectures.torch\_models.NetAeshd method)@\spxentry{set\_dim()}\spxextra{MLSCAlib.Architectures.torch\_models.NetAeshd method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.NetAeshd.set_dim}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_dim}}}{\emph{\DUrole{n}{dim}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{training (MLSCAlib.Architectures.torch\_models.NetAeshd attribute)@\spxentry{training}\spxextra{MLSCAlib.Architectures.torch\_models.NetAeshd attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.NetAeshd.training}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{training}}\sphinxbfcode{\sphinxupquote{\DUrole{p}{:}\DUrole{w}{  }bool}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{ResNet (class in MLSCAlib.Architectures.torch\_models)@\spxentry{ResNet}\spxextra{class in MLSCAlib.Architectures.torch\_models}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.ResNet}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Architectures.torch\_models.}}\sphinxbfcode{\sphinxupquote{ResNet}}}{\emph{\DUrole{n}{num\_classes}}, \emph{\DUrole{n}{ns}}, \emph{\DUrole{n}{dk}}, \emph{\DUrole{n}{noise\_std}}, \emph{\DUrole{n}{dim}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{num\_blocks}\DUrole{o}{=}\DUrole{default_value}{{[}3, 4, 6, 3{]}}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
ResNet architecture.

\sphinxAtStartPar
This architecture has been proposed by Bursztein and Picod%
\begin{footnote}[9]\sphinxAtStartFootnote
Elie Bursztein and Jean\sphinxhyphen{}Michel Picod. A hacker guide to deep learning based side channel attacks. In DEF CON, editor, \sphinxstyleemphasis{DEF CON 27}. 2019.
%
\end{footnote} and is
available here Bursztein and others%
\begin{footnote}[10]\sphinxAtStartFootnote
Elie Bursztein and others. Scaaml: side channel attacks assisted with machine learning. \sphinxurl{https://github.com/google/scaaml}, 2019.
%
\end{footnote}.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num\_classes}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of classes, depending on the leakage model.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ns}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of samples per trace.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{DK}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to use Domain Knowledge neurons or not.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{noise\_std}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} Standard deviation of the gaussian noise to add to the training traces. If set
to None, won’t add this noise.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dim}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1}}) \textendash{} If set to 0, computes the output probas on the batch. If set to 1, computes proba on
each sample separately.

\end{itemize}

\end{description}\end{quote}
\index{forward() (MLSCAlib.Architectures.torch\_models.ResNet method)@\spxentry{forward()}\spxextra{MLSCAlib.Architectures.torch\_models.ResNet method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.ResNet.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\emph{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Defines the computation performed at every call.

\sphinxAtStartPar
Should be overridden by all subclasses.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Although the recipe for forward pass needs to be defined within
this function, one should call the \sphinxcode{\sphinxupquote{Module}} instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.
\end{sphinxadmonition}

\end{fulllineitems}

\index{set\_dim() (MLSCAlib.Architectures.torch\_models.ResNet method)@\spxentry{set\_dim()}\spxextra{MLSCAlib.Architectures.torch\_models.ResNet method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.ResNet.set_dim}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_dim}}}{\emph{\DUrole{n}{dim}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{training (MLSCAlib.Architectures.torch\_models.ResNet attribute)@\spxentry{training}\spxextra{MLSCAlib.Architectures.torch\_models.ResNet attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.ResNet.training}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{training}}\sphinxbfcode{\sphinxupquote{\DUrole{p}{:}\DUrole{w}{  }bool}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{Simple\_AES\_RD (class in MLSCAlib.Architectures.torch\_models)@\spxentry{Simple\_AES\_RD}\spxextra{class in MLSCAlib.Architectures.torch\_models}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.Simple_AES_RD}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Architectures.torch\_models.}}\sphinxbfcode{\sphinxupquote{Simple\_AES\_RD}}}{\emph{\DUrole{n}{num\_classes}}, \emph{\DUrole{n}{ns}}, \emph{\DUrole{n}{dk}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{noise\_std}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{dim}\DUrole{o}{=}\DUrole{default_value}{0}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
Simplified architecture to attack AES\_RD by Wouters \sphinxstyleemphasis{et al.}%
\begin{footnote}[11]\sphinxAtStartFootnote
Lennert Wouters, Victor Arribas, Benedikt Gierlichs, and Bart Preneel. Revisiting a methodology for efficient cnn architectures in profiling attacks. \sphinxstyleemphasis{IACR Transactions on Cryptographic Hardware and Embedded Systems}, pages 147\textendash{}168, 2020.
%
\end{footnote}
\index{forward() (MLSCAlib.Architectures.torch\_models.Simple\_AES\_RD method)@\spxentry{forward()}\spxextra{MLSCAlib.Architectures.torch\_models.Simple\_AES\_RD method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.Simple_AES_RD.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\emph{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Defines the computation performed at every call.

\sphinxAtStartPar
Should be overridden by all subclasses.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Although the recipe for forward pass needs to be defined within
this function, one should call the \sphinxcode{\sphinxupquote{Module}} instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.
\end{sphinxadmonition}

\end{fulllineitems}

\index{set\_dim() (MLSCAlib.Architectures.torch\_models.Simple\_AES\_RD method)@\spxentry{set\_dim()}\spxextra{MLSCAlib.Architectures.torch\_models.Simple\_AES\_RD method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.Simple_AES_RD.set_dim}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_dim}}}{\emph{\DUrole{n}{dim}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{training (MLSCAlib.Architectures.torch\_models.Simple\_AES\_RD attribute)@\spxentry{training}\spxextra{MLSCAlib.Architectures.torch\_models.Simple\_AES\_RD attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.Simple_AES_RD.training}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{training}}\sphinxbfcode{\sphinxupquote{\DUrole{p}{:}\DUrole{w}{  }bool}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{VGG16 (class in MLSCAlib.Architectures.torch\_models)@\spxentry{VGG16}\spxextra{class in MLSCAlib.Architectures.torch\_models}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.VGG16}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Architectures.torch\_models.}}\sphinxbfcode{\sphinxupquote{VGG16}}}{\emph{\DUrole{n}{num\_classes}}, \emph{\DUrole{n}{ns}}, \emph{\DUrole{n}{dk}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{noise\_std}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{dim}\DUrole{o}{=}\DUrole{default_value}{0}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
A VGG model, as taken from Kim \sphinxstyleemphasis{et al.}%
\begin{footnote}[12]\sphinxAtStartFootnote
Jaehun Kim, Stjepan Picek, Annelie Heuser, Shivam Bhasin, and Alan Hanjalic. Make some noise. unleashing the power of convolutional neural networks for profiled side\sphinxhyphen{}channel analysis. \sphinxstyleemphasis{IACR Transactions on Cryptographic Hardware and Embedded Systems}, 2019(3):148\textendash{}179, May 2019. URL: \sphinxurl{https://tches.iacr.org/index.php/TCHES/article/view/8292}, \sphinxhref{https://doi.org/10.13154/tches.v2019.i3.148-179}{doi:10.13154/tches.v2019.i3.148\sphinxhyphen{}179}.
%
\end{footnote}.

\sphinxAtStartPar
Recommended to use a L2 reg of value 10\textasciicircum{}\sphinxhyphen{}7
\index{forward() (MLSCAlib.Architectures.torch\_models.VGG16 method)@\spxentry{forward()}\spxextra{MLSCAlib.Architectures.torch\_models.VGG16 method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.VGG16.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\emph{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Defines the computation performed at every call.

\sphinxAtStartPar
Should be overridden by all subclasses.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Although the recipe for forward pass needs to be defined within
this function, one should call the \sphinxcode{\sphinxupquote{Module}} instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.
\end{sphinxadmonition}

\end{fulllineitems}

\index{set\_dim() (MLSCAlib.Architectures.torch\_models.VGG16 method)@\spxentry{set\_dim()}\spxextra{MLSCAlib.Architectures.torch\_models.VGG16 method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.VGG16.set_dim}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_dim}}}{\emph{\DUrole{n}{dim}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{training (MLSCAlib.Architectures.torch\_models.VGG16 attribute)@\spxentry{training}\spxextra{MLSCAlib.Architectures.torch\_models.VGG16 attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.VGG16.training}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{training}}\sphinxbfcode{\sphinxupquote{\DUrole{p}{:}\DUrole{w}{  }bool}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{VGGNoise (class in MLSCAlib.Architectures.torch\_models)@\spxentry{VGGNoise}\spxextra{class in MLSCAlib.Architectures.torch\_models}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.VGGNoise}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Architectures.torch\_models.}}\sphinxbfcode{\sphinxupquote{VGGNoise}}}{\emph{\DUrole{n}{num\_classes}}, \emph{\DUrole{n}{ns}}, \emph{\DUrole{n}{dk}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{noise\_std}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{dim}\DUrole{o}{=}\DUrole{default_value}{0}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Module}}

\sphinxAtStartPar
A VGG model, as taken from Kim \sphinxstyleemphasis{et al.}\sphinxfootnotemark[12].

\sphinxAtStartPar
Authors recommended to use a L2 reg of value 10\textasciicircum{}\sphinxhyphen{}7.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{num\_classes}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of classes, depending on the leakage model.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ns}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of samples per trace.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{DK}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to use Domain Knowledge neurons or not.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{noise\_std}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} Standard deviation of the gaussian noise to add to the training traces. If set
to None, won’t add this noise.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dim}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1}}) \textendash{} If set to 0, computes the output probas on the batch. If set to 1, computes proba on
each sample separately.

\end{itemize}

\end{description}\end{quote}
\index{forward() (MLSCAlib.Architectures.torch\_models.VGGNoise method)@\spxentry{forward()}\spxextra{MLSCAlib.Architectures.torch\_models.VGGNoise method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.VGGNoise.forward}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{forward}}}{\emph{\DUrole{n}{x}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Defines the computation performed at every call.

\sphinxAtStartPar
Should be overridden by all subclasses.

\begin{sphinxadmonition}{note}{Note:}
\sphinxAtStartPar
Although the recipe for forward pass needs to be defined within
this function, one should call the \sphinxcode{\sphinxupquote{Module}} instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.
\end{sphinxadmonition}

\end{fulllineitems}

\index{set\_dim() (MLSCAlib.Architectures.torch\_models.VGGNoise method)@\spxentry{set\_dim()}\spxextra{MLSCAlib.Architectures.torch\_models.VGGNoise method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.VGGNoise.set_dim}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_dim}}}{\emph{\DUrole{n}{dim}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{training (MLSCAlib.Architectures.torch\_models.VGGNoise attribute)@\spxentry{training}\spxextra{MLSCAlib.Architectures.torch\_models.VGGNoise attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Architectures:MLSCAlib.Architectures.torch_models.VGGNoise.training}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{training}}\sphinxbfcode{\sphinxupquote{\DUrole{p}{:}\DUrole{w}{  }bool}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}


\sphinxstepscope


\subsubsection{MLSCAlib.Attacks package}
\label{\detokenize{MLSCAlib.Attacks:mlscalib-attacks-package}}\label{\detokenize{MLSCAlib.Attacks::doc}}

\paragraph{Submodules}
\label{\detokenize{MLSCAlib.Attacks:submodules}}

\paragraph{MLSCAlib.Attacks.attack module}
\label{\detokenize{MLSCAlib.Attacks:module-MLSCAlib.Attacks.attack}}\label{\detokenize{MLSCAlib.Attacks:mlscalib-attacks-attack-module}}\index{module@\spxentry{module}!MLSCAlib.Attacks.attack@\spxentry{MLSCAlib.Attacks.attack}}\index{MLSCAlib.Attacks.attack@\spxentry{MLSCAlib.Attacks.attack}!module@\spxentry{module}}\index{Attack (class in MLSCAlib.Attacks.attack)@\spxentry{Attack}\spxextra{class in MLSCAlib.Attacks.attack}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.Attack}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Attacks.attack.}}\sphinxbfcode{\sphinxupquote{Attack}}}{\emph{\DUrole{n}{model\_name}}, \emph{\DUrole{n}{batch\_size}}, \emph{\DUrole{n}{loss}}, \emph{\DUrole{n}{optimizer}}, \emph{\DUrole{n}{leakage\_model}}, \emph{\DUrole{n}{verbose}}, \emph{\DUrole{n}{lambdas}}, \emph{\DUrole{n}{dk}}, \emph{\DUrole{n}{noise}}, \emph{\DUrole{n}{seed}}, \emph{\DUrole{n}{data\_manager}}, \emph{\DUrole{n}{results\_path}}, \emph{\DUrole{n}{training}}, \emph{\DUrole{n}{info}}, \emph{\DUrole{n}{dim}}, \emph{\DUrole{n}{threshold}\DUrole{o}{=}\DUrole{default_value}{0.8}}, \emph{\DUrole{n}{lr\_schedule}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{ABC}}

\sphinxAtStartPar
The base class for any SCA Attacks in this module.

\sphinxAtStartPar
Allows to perform an attack on a chosen cipher.
\index{\_\_init\_\_() (MLSCAlib.Attacks.attack.Attack method)@\spxentry{\_\_init\_\_()}\spxextra{MLSCAlib.Attacks.attack.Attack method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.Attack.__init__}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{\emph{\DUrole{n}{model\_name}}, \emph{\DUrole{n}{batch\_size}}, \emph{\DUrole{n}{loss}}, \emph{\DUrole{n}{optimizer}}, \emph{\DUrole{n}{leakage\_model}}, \emph{\DUrole{n}{verbose}}, \emph{\DUrole{n}{lambdas}}, \emph{\DUrole{n}{dk}}, \emph{\DUrole{n}{noise}}, \emph{\DUrole{n}{seed}}, \emph{\DUrole{n}{data\_manager}}, \emph{\DUrole{n}{results\_path}}, \emph{\DUrole{n}{training}}, \emph{\DUrole{n}{info}}, \emph{\DUrole{n}{dim}}, \emph{\DUrole{n}{threshold}\DUrole{o}{=}\DUrole{default_value}{0.8}}, \emph{\DUrole{n}{lr\_schedule}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Initializes an Attack.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{model\_name}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Which NN model to use.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{batch\_size}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Batch size used during training.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{loss}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Loss function to use. Can be mse, cross\_entropy or nlll.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{optimizer}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Can be Adam or SGD.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{leakage\_model}} (\sphinxstyleliteralemphasis{\sphinxupquote{Ciphers.LeakageModel}}) \textendash{} A LeakageModel class used for label computations.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} What should be printed out during execution ? 0 : only the result,
1 : the different metrics (e.g. remaining time, sensitivities, accuracies),
2 : output debug informations too.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lambdas}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{Float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} If not None, specifies the L1 \& L2 regularization terms of two layers.
The first two values (by default 0.03,0.03) are the L1 and L2 regularization
for a model’s layer whose name is “regularized\_function\_1”. The next two values
are the L1 \& L2 regularization for any layer in the model whose name contain
“regularized\_function\_”.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dk}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} Whether to use Domain Knowledge neurons. Those add plaintext information
in the MLP part of the network.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{noise}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} Whether to add gaussian noise to the input of the training data.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{seed}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Which seed to use. If set to None, doesn’t use any seed.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{data\_manager}} (\sphinxstyleliteralemphasis{\sphinxupquote{Data.DataManager}}) \textendash{} The datamanager handles anything related to the data.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{results\_path}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Where to store the learning plots.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{training}} (\sphinxstyleliteralemphasis{\sphinxupquote{attacks.attack.TrainingMethods}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : Trainingmethods.DEFAULT}}) \textendash{} Which training method to use.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{info}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : ""}}) \textendash{} A small text to insert in the result file name.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dim}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 0}}) \textendash{} On which dimension/axis to apply the softmax filter in the NN.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{threshold}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 0.4}}) \textendash{} When the certainty is higher than this threshold, we assume the guess is correct.
To be used in blind attacks.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lr\_schedule}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{,}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]} }}\sphinxstyleliteralemphasis{\sphinxupquote{| }}\sphinxstyleliteralemphasis{\sphinxupquote{None. Default : None.}}) \textendash{} learning rate Scheduler parameter. If not None, after each lr\_schedule{[}0{]} epochs,
multiply the learning rate by lr\_schedule{[}1{]}.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{attack\_byte() (MLSCAlib.Attacks.attack.Attack method)@\spxentry{attack\_byte()}\spxextra{MLSCAlib.Attacks.attack.Attack method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.Attack.attack_byte}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{abstract\DUrole{w}{  }}}\sphinxbfcode{\sphinxupquote{attack\_byte}}}{\emph{\DUrole{n}{byte}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Attack byte: launches a full attack on a byte.

\sphinxAtStartPar
Will print the result of the attack on the terminal.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{byte}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Byte number to attack. Some bytes may be harder to attack than others.

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{GE} \textendash{} The guessing entropy.

\sphinxlineitem{Return type}
\sphinxAtStartPar
int

\end{description}\end{quote}

\end{fulllineitems}

\index{attack\_bytes() (MLSCAlib.Attacks.attack.Attack method)@\spxentry{attack\_bytes()}\spxextra{MLSCAlib.Attacks.attack.Attack method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.Attack.attack_bytes}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{abstract\DUrole{w}{  }}}\sphinxbfcode{\sphinxupquote{attack\_bytes}}}{\emph{\DUrole{n}{byte\_range}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Launches attack\_byte() method on each given byte.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{byte\_range}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{,}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} On which byte(s) to launch a SCA.

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{key\_ranking} (\sphinxstyleemphasis{List{[}int{]}}) \textendash{} The key ordered in decreased order of probability

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{key\_certainty} (\sphinxstyleemphasis{float}) \textendash{} An estimated probability that GE = 1.

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{attack\_key() (MLSCAlib.Attacks.attack.Attack method)@\spxentry{attack\_key()}\spxextra{MLSCAlib.Attacks.attack.Attack method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.Attack.attack_key}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{attack\_key}}}{\emph{\DUrole{n}{timeout}\DUrole{o}{=}\DUrole{default_value}{7200}}, \emph{\DUrole{n}{reuse\_this\_key\_probas}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Blind key attack.

\sphinxAtStartPar
Performs a real\sphinxhyphen{}setting attack on the whole key. Will first call attack\_bytes on all byte,
and then make a best\sphinxhyphen{}effort brute\sphinxhyphen{}force search to find the correct key if any ciphertext was
available in the dataset.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{timeout}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 7200}}) \textendash{} After how many seconds to stop the brute\sphinxhyphen{}force search.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{reuse\_this\_key\_probas}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} This argument should be the path to a .npy file containing a previous attack\_bytes(range(16))
result.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_GE() (MLSCAlib.Attacks.attack.Attack static method)@\spxentry{get\_GE()}\spxextra{MLSCAlib.Attacks.attack.Attack static method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.Attack.get_GE}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{static\DUrole{w}{  }}}\sphinxbfcode{\sphinxupquote{get\_GE}}}{\emph{\DUrole{n}{output\_proba\_on\_key}}, \emph{\DUrole{n}{key\_byte}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Computes the guesing entropy for one byte.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{output\_proba\_on\_key}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} List of probabilities sorted on the secret key for each plaintext.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{key\_byte}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} The value of the target key byte.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
The Guessing Entropy of the attack.

\sphinxlineitem{Return type}
\sphinxAtStartPar
int

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_GE\_from\_sensitivity() (MLSCAlib.Attacks.attack.Attack static method)@\spxentry{get\_GE\_from\_sensitivity()}\spxextra{MLSCAlib.Attacks.attack.Attack static method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.Attack.get_GE_from_sensitivity}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{static\DUrole{w}{  }}}\sphinxbfcode{\sphinxupquote{get\_GE\_from\_sensitivity}}}{\emph{\DUrole{n}{sensitivity}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Computes the GE of the non profiling process for one byte.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{sensitivities}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} List of sensitivities, ** with the sensitivity of the right key at the end.**

\sphinxlineitem{Returns}
\sphinxAtStartPar
The Guessing Entropy of the attack

\sphinxlineitem{Return type}
\sphinxAtStartPar
int

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_accuracy() (MLSCAlib.Attacks.attack.Attack method)@\spxentry{get\_accuracy()}\spxextra{MLSCAlib.Attacks.attack.Attack method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.Attack.get_accuracy}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_accuracy}}}{\emph{\DUrole{n}{preds}}, \emph{\DUrole{n}{labels}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Get accuracy: computes the prediction’s accuracy.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{preds}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Model predictions, i.e. probability distribution of each class.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{labels}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Labels corresponding to each prediction. May or not be in categorical form.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
The prediction accuracy.

\sphinxlineitem{Return type}
\sphinxAtStartPar
float

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_fast\_GE() (MLSCAlib.Attacks.attack.Attack method)@\spxentry{get\_fast\_GE()}\spxextra{MLSCAlib.Attacks.attack.Attack method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.Attack.get_fast_GE}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_fast\_GE}}}{\emph{\DUrole{n}{model}}, \emph{\DUrole{n}{traces}}, \emph{\DUrole{n}{plaintext\_attack}}, \emph{\DUrole{n}{byte}}, \emph{\DUrole{n}{key\_byte}}, \emph{\DUrole{n}{fast\_size}\DUrole{o}{=}\DUrole{default_value}{500}}, \emph{\DUrole{n}{masks}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Computes the fats guessing entropy by only considering a subset of the plaintexts/keys.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{model}} (\sphinxstyleliteralemphasis{\sphinxupquote{tensorflow.keras.models}}) \textendash{} ML model.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{traces}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Validation/attack traces.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{plaintext\_attack}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Validation or attack plaintexts.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{byte}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Target byte index.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{key\_byte}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} The value of the target key byte

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fast\_size}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 500}}) \textendash{} How many traces to consider at maximum to compute the Guessing Entropy.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
Returns the Guessing Entropy on a subset of the traces.

\sphinxlineitem{Return type}
\sphinxAtStartPar
int

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_keys\_from\_probas() (MLSCAlib.Attacks.attack.Attack static method)@\spxentry{get\_keys\_from\_probas()}\spxextra{MLSCAlib.Attacks.attack.Attack static method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.Attack.get_keys_from_probas}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{static\DUrole{w}{  }}}\sphinxbfcode{\sphinxupquote{get\_keys\_from\_probas}}}{\emph{\DUrole{n}{output\_proba\_on\_key}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{get\_keys\_from\_sensitivity() (MLSCAlib.Attacks.attack.Attack static method)@\spxentry{get\_keys\_from\_sensitivity()}\spxextra{MLSCAlib.Attacks.attack.Attack static method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.Attack.get_keys_from_sensitivity}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{static\DUrole{w}{  }}}\sphinxbfcode{\sphinxupquote{get\_keys\_from\_sensitivity}}}{\emph{\DUrole{n}{sensitivity}}, \emph{\DUrole{n}{keys}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Computes the ranking of the keys given sensitivity values.

\sphinxAtStartPar
This function is to be used in blind attacks.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{sensitivities}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} List of sensitivities.

\sphinxlineitem{Returns}
\sphinxAtStartPar
The ranking of the keys.

\sphinxlineitem{Return type}
\sphinxAtStartPar
int

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_pruning\_percentage() (MLSCAlib.Attacks.attack.Attack method)@\spxentry{get\_pruning\_percentage()}\spxextra{MLSCAlib.Attacks.attack.Attack method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.Attack.get_pruning_percentage}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{abstract\DUrole{w}{  }}}\sphinxbfcode{\sphinxupquote{get\_pruning\_percentage}}}{}{}
\pysigstopsignatures
\end{fulllineitems}

\index{get\_sensitivity\_tensors() (MLSCAlib.Attacks.attack.Attack method)@\spxentry{get\_sensitivity\_tensors()}\spxextra{MLSCAlib.Attacks.attack.Attack method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.Attack.get_sensitivity_tensors}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_sensitivity\_tensors}}}{\emph{\DUrole{n}{model}}, \emph{\DUrole{n}{traces}}, \emph{\DUrole{n}{labels}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Computes the sensitivity value, as from Timon%
\begin{footnote}[1]\sphinxAtStartFootnote
Benjamin Timon. Non\sphinxhyphen{}profiled deep learning\sphinxhyphen{}based side\sphinxhyphen{}channel attacks with sensitivity analysis. \sphinxstyleemphasis{IACR Transactions on Cryptographic Hardware and Embedded Systems}, 2019(2):107\textendash{}131, February 2019. URL: \sphinxurl{https://tches.iacr.org/index.php/TCHES/article/view/7387}, \sphinxhref{https://doi.org/10.13154/tches.v2019.i2.107-131}{doi:10.13154/tches.v2019.i2.107\sphinxhyphen{}131}.
%
\end{footnote}.

\sphinxAtStartPar
It is computed using the derivative of the loss function with respect to the input.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{model}} (\sphinxstyleliteralemphasis{\sphinxupquote{torch.nn.Module}}) \textendash{} The trained model.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{traces}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} The power traces.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{labels}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} The training labels.

\end{itemize}

\sphinxlineitem{Raises}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{AttributeError}} \textendash{} If the traces do not requires\_grad().

\sphinxlineitem{Returns}
\sphinxAtStartPar
A tensor of size ns with the according sensitivity values.

\sphinxlineitem{Return type}
\sphinxAtStartPar
torch.tensor

\end{description}\end{quote}

\end{fulllineitems}

\index{set\_pruning\_percentage() (MLSCAlib.Attacks.attack.Attack method)@\spxentry{set\_pruning\_percentage()}\spxextra{MLSCAlib.Attacks.attack.Attack method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.Attack.set_pruning_percentage}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_pruning\_percentage}}}{\emph{\DUrole{n}{percentage}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{set\_seed() (MLSCAlib.Attacks.attack.Attack method)@\spxentry{set\_seed()}\spxextra{MLSCAlib.Attacks.attack.Attack method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.Attack.set_seed}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_seed}}}{\emph{\DUrole{n}{seed}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Sets the seed.

\sphinxAtStartPar
Fixes the randomness of each component of the attack, allowing reproducibility of results.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{seed}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} 

\end{description}\end{quote}

\end{fulllineitems}

\index{train\_model\_default() (MLSCAlib.Attacks.attack.Attack method)@\spxentry{train\_model\_default()}\spxextra{MLSCAlib.Attacks.attack.Attack method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.Attack.train_model_default}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{abstract\DUrole{w}{  }}}\sphinxbfcode{\sphinxupquote{train\_model\_default}}}{\emph{\DUrole{o}{**}\DUrole{n}{kwargs}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Default methods for training.

\end{fulllineitems}

\index{train\_model\_pruning() (MLSCAlib.Attacks.attack.Attack method)@\spxentry{train\_model\_pruning()}\spxextra{MLSCAlib.Attacks.attack.Attack method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.Attack.train_model_pruning}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{train\_model\_pruning}}}{\emph{\DUrole{n}{x\_prof}}, \emph{\DUrole{n}{label\_prof}}, \emph{\DUrole{n}{x\_prof\_val}}, \emph{\DUrole{n}{label\_prof\_val}}, \emph{\DUrole{n}{plaintext\_prof\_val}}, \emph{\DUrole{n}{mask\_val}}, \emph{\DUrole{n}{key}}, \emph{\DUrole{n}{byte}}, \emph{\DUrole{n}{model}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{get\_metrics}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{fast}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{sensi\_reg}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{fast\_sensi}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Trains the model using LTH pruning methods.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{x\_prof}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}) \textendash{} The attack traces used for unprofiled training. Should have the shape (Na,1,Ns).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{label\_prof}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} The labels corresponding to label\_prof.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{x\_prof\_val}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}) \textendash{} Traces to use for metrics computations (e.g. sensitivity computation). Can be
the same as x\_prof.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{label\_prof\_val}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} The labels corresponding to x\_prof\_val.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{List}}\sphinxstyleliteralstrong{\sphinxupquote{{[}}}\sphinxstyleliteralstrong{\sphinxupquote{int}}\sphinxstyleliteralstrong{\sphinxupquote{{]}}} (\sphinxstyleliteralemphasis{\sphinxupquote{plaintext\_prof\_val ;}}) \textendash{} The plaintexts corresponding to x\_prof\_val

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{key}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} The attack key(s).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{byte}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Target byte index.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{model}} (\sphinxstyleliteralemphasis{\sphinxupquote{nn.Module}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} If not set to None, will re\sphinxhyphen{}use the model given instaed of creating a new.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{get\_metrics}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : True}}) \textendash{} Whether to calculate validation accuracy and training accuracy.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fast}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to calculate the fast Guessing Entropy during learning. May induce
additionnal delays.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{model} \textendash{} The trained model.

\sphinxlineitem{Return type}
\sphinxAtStartPar
torch.nn.Module

\end{description}\end{quote}

\end{fulllineitems}

\index{turn\_output\_probas\_to\_key\_proba() (MLSCAlib.Attacks.attack.Attack method)@\spxentry{turn\_output\_probas\_to\_key\_proba()}\spxextra{MLSCAlib.Attacks.attack.Attack method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.Attack.turn_output_probas_to_key_proba}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{turn\_output\_probas\_to\_key\_proba}}}{\emph{\DUrole{n}{output\_probas}}, \emph{\DUrole{n}{plaintexts}}, \emph{\DUrole{n}{byte\_position}}, \emph{\DUrole{n}{masks}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\pysigstopsignatures\begin{description}
\sphinxlineitem{Turns the probabilities from being a probability on the value of the label sorted on the label, to a probability}
\sphinxAtStartPar
on the secret key sorted with the secret key. In case of huge datasets, will use multiprocessing.

\end{description}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{output\_probas}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} Output probabilites of the ML model (model.predict(x\_attack)) with to\_categorical y\_train data.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{plaintexts}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} List of plaintexts.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{byte\_position}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} The target byte index.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
List of probabilities sorted on the secret key for each plaintext

\sphinxlineitem{Return type}
\sphinxAtStartPar
List{[}List{[}float{]}{]}

\sphinxlineitem{Raises}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{Errors}} \textendash{} When the data went through GPU memory and back to cpu via tensor.cpu().numpy() and
    a parallel computing is launched.
    When the CPU memory is being exhausted.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{SensitivityMode (class in MLSCAlib.Attacks.attack)@\spxentry{SensitivityMode}\spxextra{class in MLSCAlib.Attacks.attack}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.SensitivityMode}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Attacks.attack.}}\sphinxbfcode{\sphinxupquote{SensitivityMode}}}{\emph{\DUrole{n}{value}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Enum}}

\sphinxAtStartPar
An enumeration.
\index{ABSOLUTE\_VALUES (MLSCAlib.Attacks.attack.SensitivityMode attribute)@\spxentry{ABSOLUTE\_VALUES}\spxextra{MLSCAlib.Attacks.attack.SensitivityMode attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.SensitivityMode.ABSOLUTE_VALUES}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{ABSOLUTE\_VALUES}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }1}}}
\pysigstopsignatures
\end{fulllineitems}

\index{CLASSIC (MLSCAlib.Attacks.attack.SensitivityMode attribute)@\spxentry{CLASSIC}\spxextra{MLSCAlib.Attacks.attack.SensitivityMode attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.SensitivityMode.CLASSIC}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{CLASSIC}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }0}}}
\pysigstopsignatures
\end{fulllineitems}

\index{GRAD\_CAM (MLSCAlib.Attacks.attack.SensitivityMode attribute)@\spxentry{GRAD\_CAM}\spxextra{MLSCAlib.Attacks.attack.SensitivityMode attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.SensitivityMode.GRAD_CAM}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{GRAD\_CAM}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }3}}}
\pysigstopsignatures
\end{fulllineitems}

\index{GRAD\_CAM\_PLUS\_PLUS (MLSCAlib.Attacks.attack.SensitivityMode attribute)@\spxentry{GRAD\_CAM\_PLUS\_PLUS}\spxextra{MLSCAlib.Attacks.attack.SensitivityMode attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.SensitivityMode.GRAD_CAM_PLUS_PLUS}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{GRAD\_CAM\_PLUS\_PLUS}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }4}}}
\pysigstopsignatures
\end{fulllineitems}

\index{ON\_RAW\_TRACE (MLSCAlib.Attacks.attack.SensitivityMode attribute)@\spxentry{ON\_RAW\_TRACE}\spxextra{MLSCAlib.Attacks.attack.SensitivityMode attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.SensitivityMode.ON_RAW_TRACE}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{ON\_RAW\_TRACE}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }2}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}

\index{TrainingMethods (class in MLSCAlib.Attacks.attack)@\spxentry{TrainingMethods}\spxextra{class in MLSCAlib.Attacks.attack}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.TrainingMethods}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Attacks.attack.}}\sphinxbfcode{\sphinxupquote{TrainingMethods}}}{\emph{\DUrole{n}{value}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Enum}}

\sphinxAtStartPar
An enumeration.
\index{ADVERSARIAL (MLSCAlib.Attacks.attack.TrainingMethods attribute)@\spxentry{ADVERSARIAL}\spxextra{MLSCAlib.Attacks.attack.TrainingMethods attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.TrainingMethods.ADVERSARIAL}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{ADVERSARIAL}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }2}}}
\pysigstopsignatures
\end{fulllineitems}

\index{CROSS\_VALIDATION (MLSCAlib.Attacks.attack.TrainingMethods attribute)@\spxentry{CROSS\_VALIDATION}\spxextra{MLSCAlib.Attacks.attack.TrainingMethods attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.TrainingMethods.CROSS_VALIDATION}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{CROSS\_VALIDATION}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }4}}}
\pysigstopsignatures
\end{fulllineitems}

\index{CUSTOM (MLSCAlib.Attacks.attack.TrainingMethods attribute)@\spxentry{CUSTOM}\spxextra{MLSCAlib.Attacks.attack.TrainingMethods attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.TrainingMethods.CUSTOM}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{CUSTOM}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }5}}}
\pysigstopsignatures
\end{fulllineitems}

\index{DEFAULT (MLSCAlib.Attacks.attack.TrainingMethods attribute)@\spxentry{DEFAULT}\spxextra{MLSCAlib.Attacks.attack.TrainingMethods attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.TrainingMethods.DEFAULT}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{DEFAULT}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }0}}}
\pysigstopsignatures
\sphinxAtStartPar
Default training.

\end{fulllineitems}

\index{MIXUP (MLSCAlib.Attacks.attack.TrainingMethods attribute)@\spxentry{MIXUP}\spxextra{MLSCAlib.Attacks.attack.TrainingMethods attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.TrainingMethods.MIXUP}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{MIXUP}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }3}}}
\pysigstopsignatures
\end{fulllineitems}

\index{PRUNING\_GLOBAL (MLSCAlib.Attacks.attack.TrainingMethods attribute)@\spxentry{PRUNING\_GLOBAL}\spxextra{MLSCAlib.Attacks.attack.TrainingMethods attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.TrainingMethods.PRUNING_GLOBAL}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{PRUNING\_GLOBAL}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }5}}}
\pysigstopsignatures
\sphinxAtStartPar
LTH pruning done on the whole model. May disable entire layers.

\end{fulllineitems}

\index{PRUNING\_HALF\_EPOCHS\_GLOBAL (MLSCAlib.Attacks.attack.TrainingMethods attribute)@\spxentry{PRUNING\_HALF\_EPOCHS\_GLOBAL}\spxextra{MLSCAlib.Attacks.attack.TrainingMethods attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.TrainingMethods.PRUNING_HALF_EPOCHS_GLOBAL}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{PRUNING\_HALF\_EPOCHS\_GLOBAL}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }5.5}}}
\pysigstopsignatures
\sphinxAtStartPar
LTH pruning done on the whole model. May disable entire layers. Uses only half as many epochs in the second training.

\end{fulllineitems}

\index{PRUNING\_HALF\_EPOCHS\_LOCAL (MLSCAlib.Attacks.attack.TrainingMethods attribute)@\spxentry{PRUNING\_HALF\_EPOCHS\_LOCAL}\spxextra{MLSCAlib.Attacks.attack.TrainingMethods attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.TrainingMethods.PRUNING_HALF_EPOCHS_LOCAL}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{PRUNING\_HALF\_EPOCHS\_LOCAL}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }1.5}}}
\pysigstopsignatures
\sphinxAtStartPar
LTH pruning done layer\sphinxhyphen{}wise, using only half as many epochs in the second training.

\end{fulllineitems}

\index{PRUNING\_LOCAL (MLSCAlib.Attacks.attack.TrainingMethods attribute)@\spxentry{PRUNING\_LOCAL}\spxextra{MLSCAlib.Attacks.attack.TrainingMethods attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.TrainingMethods.PRUNING_LOCAL}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{PRUNING\_LOCAL}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }1}}}
\pysigstopsignatures
\sphinxAtStartPar
LTH pruning done layer\sphinxhyphen{}wise.

\end{fulllineitems}


\end{fulllineitems}



\paragraph{MLSCAlib.Attacks.unprofiled module}
\label{\detokenize{MLSCAlib.Attacks:module-MLSCAlib.Attacks.unprofiled}}\label{\detokenize{MLSCAlib.Attacks:mlscalib-attacks-unprofiled-module}}\index{module@\spxentry{module}!MLSCAlib.Attacks.unprofiled@\spxentry{MLSCAlib.Attacks.unprofiled}}\index{MLSCAlib.Attacks.unprofiled@\spxentry{MLSCAlib.Attacks.unprofiled}!module@\spxentry{module}}\index{UnProfiled (class in MLSCAlib.Attacks.unprofiled)@\spxentry{UnProfiled}\spxextra{class in MLSCAlib.Attacks.unprofiled}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.unprofiled.UnProfiled}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Attacks.unprofiled.}}\sphinxbfcode{\sphinxupquote{UnProfiled}}}{\emph{epochs=15, model\_name=\textquotesingle{}mlp\textquotesingle{}, batch\_size=100, loss=\textquotesingle{}nlll\textquotesingle{}, optimizer=\textquotesingle{}Adam\textquotesingle{}, leakage\_model=HW(SBox), verbose=1, lambdas={[}0.03, 0.03, 0.0008, 0.0008{]}, dk=False, noise=False, seed=None, split\_non\_profiling\_attack\_set=True, sensitivity\_mode=SensitivityMode.CLASSIC, data\_manager=\{\textquotesingle{}force\_cpu\textquotesingle{}: False, \textquotesingle{}remove\_mask\textquotesingle{}: False, \textquotesingle{}state\textquotesingle{}: \textless{}\_StateMachine.CREATION: 0\textgreater{}, \textquotesingle{}file\_name\_attack\textquotesingle{}: \textquotesingle{}file\_name\_attack.h5\textquotesingle{}, \textquotesingle{}file\_name\_profiling\textquotesingle{}: None, \textquotesingle{}databases\_path\textquotesingle{}: \textquotesingle{}/path/to/Databases/\textquotesingle{}, \textquotesingle{}data\textquotesingle{}: None, \textquotesingle{}has\_countermeasures\textquotesingle{}: False, \textquotesingle{}\_poi\textquotesingle{}: None, \textquotesingle{}na\textquotesingle{}: None, \textquotesingle{}\_ns\textquotesingle{}: None, \textquotesingle{}nt\textquotesingle{}: 0, \textquotesingle{}fs\textquotesingle{}: 0, \textquotesingle{}blind\textquotesingle{}: False, \textquotesingle{}check\_data\textquotesingle{}: (None, None), \textquotesingle{}profiling\textquotesingle{}: False, \textquotesingle{}device\textquotesingle{}: device(type=\textquotesingle{}cuda\textquotesingle{}, index=1)\}, results\_path=\textquotesingle{}/path/to/PlotsResults/\textquotesingle{}, training=TrainingMethods.DEFAULT, info=\textquotesingle{}\textquotesingle{}, dim=0, LTH=0.8, lr\_schedule=None}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Attack}}
\index{\_\_init\_\_() (MLSCAlib.Attacks.unprofiled.UnProfiled method)@\spxentry{\_\_init\_\_()}\spxextra{MLSCAlib.Attacks.unprofiled.UnProfiled method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.unprofiled.UnProfiled.__init__}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{\emph{epochs=15, model\_name=\textquotesingle{}mlp\textquotesingle{}, batch\_size=100, loss=\textquotesingle{}nlll\textquotesingle{}, optimizer=\textquotesingle{}Adam\textquotesingle{}, leakage\_model=HW(SBox), verbose=1, lambdas={[}0.03, 0.03, 0.0008, 0.0008{]}, dk=False, noise=False, seed=None, split\_non\_profiling\_attack\_set=True, sensitivity\_mode=SensitivityMode.CLASSIC, data\_manager=\{\textquotesingle{}force\_cpu\textquotesingle{}: False, \textquotesingle{}remove\_mask\textquotesingle{}: False, \textquotesingle{}state\textquotesingle{}: \textless{}\_StateMachine.CREATION: 0\textgreater{}, \textquotesingle{}file\_name\_attack\textquotesingle{}: \textquotesingle{}file\_name\_attack.h5\textquotesingle{}, \textquotesingle{}file\_name\_profiling\textquotesingle{}: None, \textquotesingle{}databases\_path\textquotesingle{}: \textquotesingle{}/path/to/Databases/\textquotesingle{}, \textquotesingle{}data\textquotesingle{}: None, \textquotesingle{}has\_countermeasures\textquotesingle{}: False, \textquotesingle{}\_poi\textquotesingle{}: None, \textquotesingle{}na\textquotesingle{}: None, \textquotesingle{}\_ns\textquotesingle{}: None, \textquotesingle{}nt\textquotesingle{}: 0, \textquotesingle{}fs\textquotesingle{}: 0, \textquotesingle{}blind\textquotesingle{}: False, \textquotesingle{}check\_data\textquotesingle{}: (None, None), \textquotesingle{}profiling\textquotesingle{}: False, \textquotesingle{}device\textquotesingle{}: device(type=\textquotesingle{}cuda\textquotesingle{}, index=1)\}, results\_path=\textquotesingle{}/path/to/PlotsResults/\textquotesingle{}, training=TrainingMethods.DEFAULT, info=\textquotesingle{}\textquotesingle{}, dim=0, LTH=0.8, lr\_schedule=None}}{}
\pysigstopsignatures
\sphinxAtStartPar
Initializes an Attack.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{epochs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 50}}) \textendash{} How many epochs to train the NN.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{model\_name}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : mlp}}) \textendash{} Which NN model to use.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{batch\_size}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 100}}) \textendash{} Batch size used during training.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{loss}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : nlll}}) \textendash{} Loss function to use. Can be mse, cross\_entropy or nlll.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{optimizer}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : Adam}}) \textendash{} Can be Adam or SGD.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{leakage\_model}} (\sphinxstyleliteralemphasis{\sphinxupquote{Ciphers.LeakageModel}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : HW}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{SBox}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}) \textendash{} A LeakageModel class used for label computations.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1}}) \textendash{} What should be printed out during execution ? 0 : only the result,
1 : the different metrics (e.g. remaining time, sensitivities, accuracies),
2 : output debug informations too.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lambdas}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{Float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default :}}\sphinxstyleliteralemphasis{\sphinxupquote{ {[}}}\sphinxstyleliteralemphasis{\sphinxupquote{0.03}}\sphinxstyleliteralemphasis{\sphinxupquote{,}}\sphinxstyleliteralemphasis{\sphinxupquote{0.03}}\sphinxstyleliteralemphasis{\sphinxupquote{,}}\sphinxstyleliteralemphasis{\sphinxupquote{0.0008}}\sphinxstyleliteralemphasis{\sphinxupquote{,}}\sphinxstyleliteralemphasis{\sphinxupquote{0.0008}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} If not None, specifies the L1 \& L2 regularization terms of two layers.
The first two values (by default 0.03,0.03) are the L1 and L2 regularization
for a model’s layer whose name is “regularized\_function\_1”. The next two values
are the L1 \& L2 regularization for any layer in the model whose name contain
“regularized\_function\_”.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dk}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to use Domain Knowledge neurons. Those add plaintext information
in the MLP part of the network.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{noise}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to add gaussian noise to the input of the training data.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{seed}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} Which seed to use. If set to None, will use a default standard value of 5437.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{split\_non\_profiling\_attack\_set}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : True}}) \textendash{} Whether to separate the training data from the data used to calculate the
sensitivity and validation accuracies. If you plan to use a MeshNN, setting it
to False will avoid Errors.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{sensitivity\_mode}} ({\hyperref[\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.attack.SensitivityMode}]{\sphinxcrossref{\sphinxstyleliteralemphasis{\sphinxupquote{SensitivityMode}}}}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : SensitivityMode.CLASSIC}}) \textendash{} Which algorithm to choose for the sensitivity calculation.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{data\_manager}} (\sphinxstyleliteralemphasis{\sphinxupquote{Data.DataManager}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : DataManager}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}) \textendash{} The datamanager handles anything related to the data.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{results\_path}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : "/path/to/PlotsResults/"}}) \textendash{} Where to store the learning plots.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{training}} (\sphinxstyleliteralemphasis{\sphinxupquote{attacks.attack.TrainingMethods}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : TrainingMethods.DEFAULT}}) \textendash{} Which training method to use.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{info}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : ""}}) \textendash{} A small text to insert in the result file name.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dim}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 0}}) \textendash{} On which dimension/axis to apply the softmax filter in the NN.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{LTH}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 0.7}}) \textendash{} Percentage of the weights to mask in the LTH pruning. Only used if the training
method is set to TrainingMethods.PRUNING or TrainingMethods.PRUNING\_HALF\_EPOCHS.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lr\_schedule}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{,}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]} }}\sphinxstyleliteralemphasis{\sphinxupquote{| }}\sphinxstyleliteralemphasis{\sphinxupquote{None. Default : None.}}) \textendash{} learning rate Scheduler parameter. If not None, after each lr\_schedule{[}0{]} epochs,
multiply the learning rate by lr\_schedule{[}1{]}.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{attack\_byte() (MLSCAlib.Attacks.unprofiled.UnProfiled method)@\spxentry{attack\_byte()}\spxextra{MLSCAlib.Attacks.unprofiled.UnProfiled method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.unprofiled.UnProfiled.attack_byte}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{attack\_byte}}}{\emph{\DUrole{n}{byte}}, \emph{\DUrole{n}{guess\_list}\DUrole{o}{=}\DUrole{default_value}{range(0, 256)}}, \emph{\DUrole{n}{display\_sensi\_hist}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{split\_rate}\DUrole{o}{=}\DUrole{default_value}{0.88}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Attack byte: launches a full attack on a byte.

\sphinxAtStartPar
Will print the result of the attack on the terminal.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{byte}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} byte number to attack. Some bytes are harder to attack.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{guess\_list}} (\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default: range}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{256}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}) \textendash{} Against which byte values to compare the right key guess.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{display\_sensi\_hist}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to prompt a window tieh the history of the sensitivities across the epochs.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{split\_rate}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 0.88}}) \textendash{} Which percentage of the traces to discard during training and use for validation.
Warning: if you use a MeshNN, set it carefully !

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
The guessing entropy.

\sphinxlineitem{Return type}
\sphinxAtStartPar
int

\end{description}\end{quote}

\end{fulllineitems}

\index{attack\_byte\_with\_min\_traces() (MLSCAlib.Attacks.unprofiled.UnProfiled method)@\spxentry{attack\_byte\_with\_min\_traces()}\spxextra{MLSCAlib.Attacks.unprofiled.UnProfiled method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.unprofiled.UnProfiled.attack_byte_with_min_traces}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{attack\_byte\_with\_min\_traces}}}{\emph{\DUrole{n}{byte}}, \emph{\DUrole{n}{guess\_list}\DUrole{o}{=}\DUrole{default_value}{range(0, 256)}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Deprecated. Function to guess a key byte.

\sphinxAtStartPar
Performs an unprofiled ML SCA as described in Timon\sphinxfootnotemark[1] and
Kuroda \sphinxstyleemphasis{et al.}%
\begin{footnote}[2]\sphinxAtStartFootnote
Kunihiro Kuroda, Yuta Fukuda, Kota Yoshida, and Takeshi Fujino. Practical aspects on non\sphinxhyphen{}profiled deep\sphinxhyphen{}learning side\sphinxhyphen{}channel attacks against aes software implementation with two types of masking countermeasures including rsm. In \sphinxstyleemphasis{Proceedings of the 5th Workshop on Attacks and Solutions in Hardware Security}, ASHES ‘21, 29\textendash{}40. New York, NY, USA, 2021. Association for Computing Machinery. URL: \sphinxurl{https://doi.org/10.1145/3474376.3487285}, \sphinxhref{https://doi.org/10.1145/3474376.3487285}{doi:10.1145/3474376.3487285}.
%
\end{footnote}. It will train each model (resp. to a key guess)
with 1 batch until the GE equals 1. Warning: if the guess range (self.guess\_range) is too
small, the result may look random.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{byte}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} byte number to attack. The 3,12 and 14 are the most difficult  Kuroda \sphinxstyleemphasis{et al.}\sphinxfootnotemark[2].

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{guess\_list}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default: range}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{256}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}) \textendash{} Against which byte values to compare the right key guess.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
Returns a list of sensitivities, of size {[}(self.guess\_range,ns){]}

\sphinxlineitem{Return type}
\sphinxAtStartPar
List{[}float{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{attack\_bytes() (MLSCAlib.Attacks.unprofiled.UnProfiled method)@\spxentry{attack\_bytes()}\spxextra{MLSCAlib.Attacks.unprofiled.UnProfiled method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.unprofiled.UnProfiled.attack_bytes}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{attack\_bytes}}}{\emph{\DUrole{n}{byte\_range}}, \emph{\DUrole{n}{guess\_list}\DUrole{o}{=}\DUrole{default_value}{range(0, 256)}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Launches attack\_byte() method on each given byte.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{byte\_range}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{,}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} On which byte(s) to launch a SCA.

\end{description}\end{quote}

\end{fulllineitems}

\index{attack\_bytes\_with\_min\_traces() (MLSCAlib.Attacks.unprofiled.UnProfiled method)@\spxentry{attack\_bytes\_with\_min\_traces()}\spxextra{MLSCAlib.Attacks.unprofiled.UnProfiled method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.unprofiled.UnProfiled.attack_bytes_with_min_traces}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{attack\_bytes\_with\_min\_traces}}}{\emph{\DUrole{n}{byte\_range}}, \emph{\DUrole{n}{guess\_list}\DUrole{o}{=}\DUrole{default_value}{range(0, 256)}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Launches attack\_byte\_with\_min\_traces() method on each given byte.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{byte\_range}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{,}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} On which byte(s) to launch a SCA.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{guess\_list}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default: range}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{256}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}) \textendash{} Against which byte values to compare the right key guess.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_pruning\_percentage() (MLSCAlib.Attacks.unprofiled.UnProfiled method)@\spxentry{get\_pruning\_percentage()}\spxextra{MLSCAlib.Attacks.unprofiled.UnProfiled method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.unprofiled.UnProfiled.get_pruning_percentage}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_pruning\_percentage}}}{}{}
\pysigstopsignatures
\end{fulllineitems}

\index{train\_model\_adversarial() (MLSCAlib.Attacks.unprofiled.UnProfiled method)@\spxentry{train\_model\_adversarial()}\spxextra{MLSCAlib.Attacks.unprofiled.UnProfiled method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.unprofiled.UnProfiled.train_model_adversarial}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{train\_model\_adversarial}}}{}{}
\pysigstopsignatures
\end{fulllineitems}

\index{train\_model\_cross\_validation() (MLSCAlib.Attacks.unprofiled.UnProfiled method)@\spxentry{train\_model\_cross\_validation()}\spxextra{MLSCAlib.Attacks.unprofiled.UnProfiled method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.unprofiled.UnProfiled.train_model_cross_validation}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{train\_model\_cross\_validation}}}{}{}
\pysigstopsignatures
\end{fulllineitems}

\index{train\_model\_default() (MLSCAlib.Attacks.unprofiled.UnProfiled method)@\spxentry{train\_model\_default()}\spxextra{MLSCAlib.Attacks.unprofiled.UnProfiled method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.unprofiled.UnProfiled.train_model_default}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{train\_model\_default}}}{\emph{\DUrole{n}{x\_attack}}, \emph{\DUrole{n}{label\_attack}}, \emph{\DUrole{n}{x\_attack\_val}}, \emph{\DUrole{n}{label\_attack\_val}}, \emph{\DUrole{n}{plaintext\_attack\_val}}, \emph{\DUrole{n}{key\_guess}}, \emph{\DUrole{n}{byte}}, \emph{\DUrole{n}{model}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{get\_metrics}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{fast}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{sensi\_reg}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{fast\_sensi}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Trains the model
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{x\_attack}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}) \textendash{} The attack traces used for unprofiled training. Should have the shape (Na,1,Ns).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{label\_attack}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} The labels corresponding to x\_attack.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{x\_attack\_val}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}) \textendash{} Traces to use for metrics computations (e.g. sensitivity computation). Can be
the same as x\_attack.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{label\_attack\_val}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} The labels corresponding to x\_attack\_val.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{plaintext\_attack\_val}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} The plaintexts corresponding to x\_attack\_val.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{key\_guess}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Value of the guessed key byte.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{byte}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Target byte index.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{model}} (\sphinxstyleliteralemphasis{\sphinxupquote{torch.nn.Module}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} In case of gradual learning (i.e. when you want to re\sphinxhyphen{}use a previous model and train it again).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{get\_metrics}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : True}}) \textendash{} Whether to calculate training metrics such as the sensitivity and accuracy.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fast}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to calculate the Fast GE training metric. It will slow down the computation. If set to
False, it will return the loss value at each epoch instead of the GE.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{sensi\_reg}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to sue sensitivity as a regularization technique.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fast\_sensi}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to return, for each epoch, the maximum sensitivity spike for each guess. (Not implemented yet !)

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{model} (\sphinxstyleemphasis{torch.nn.Module}) \textendash{} The trained model.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{sensitivity} (\sphinxstyleemphasis{numpy.array}) \textendash{} The sum over each epoch of the sensitivity values. If get\_metric is False, an empty list is returned.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{accuracies} (\sphinxstyleemphasis{List}) \textendash{} The accuracies for each epoch. If get\_metric is False, an empty list is returned.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{fast\_GEs} (\sphinxstyleemphasis{List}) \textendash{} The fast Guessing entropy for each epoch. If get\_metric is False, an empty list is returned.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{train\_acc} (\sphinxstyleemphasis{List}) \textendash{} The training accuracy for each epoch. If get\_metric is False, an empty list is returned.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{sensi\_slider} (\sphinxstyleemphasis{List{[}List{]}}) \textendash{} A List containing the history of the sensitivity evolution through the epochs.

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{display\_sensi\_slider() (in module MLSCAlib.Attacks.unprofiled)@\spxentry{display\_sensi\_slider()}\spxextra{in module MLSCAlib.Attacks.unprofiled}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.unprofiled.display_sensi_slider}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{MLSCAlib.Attacks.unprofiled.}}\sphinxbfcode{\sphinxupquote{display\_sensi\_slider}}}{\emph{\DUrole{n}{sensitivities\_slider}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Function to display an interactive history of the sensitivity w.r.t. the epoch number.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{sensitivities\_slider}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} The accumulated sensitivity values for each epoch.

\end{description}\end{quote}

\end{fulllineitems}



\paragraph{MLSCAlib.Attacks.profiled module}
\label{\detokenize{MLSCAlib.Attacks:module-MLSCAlib.Attacks.profiled}}\label{\detokenize{MLSCAlib.Attacks:mlscalib-attacks-profiled-module}}\index{module@\spxentry{module}!MLSCAlib.Attacks.profiled@\spxentry{MLSCAlib.Attacks.profiled}}\index{MLSCAlib.Attacks.profiled@\spxentry{MLSCAlib.Attacks.profiled}!module@\spxentry{module}}\index{Profiled (class in MLSCAlib.Attacks.profiled)@\spxentry{Profiled}\spxextra{class in MLSCAlib.Attacks.profiled}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.profiled.Profiled}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Attacks.profiled.}}\sphinxbfcode{\sphinxupquote{Profiled}}}{\emph{\DUrole{n}{epochs=15}}, \emph{\DUrole{n}{model\_name=\textquotesingle{}mlp\textquotesingle{}}}, \emph{\DUrole{n}{batch\_size=100}}, \emph{\DUrole{n}{loss=\textquotesingle{}nlll\textquotesingle{}}}, \emph{\DUrole{n}{optimizer=\textquotesingle{}Adam\textquotesingle{}}}, \emph{\DUrole{n}{leakage\_model=ID(SBox)}}, \emph{\DUrole{n}{verbose=1}}, \emph{\DUrole{n}{lambdas=None}}, \emph{\DUrole{n}{dk=False}}, \emph{\DUrole{n}{noise=False}}, \emph{\DUrole{n}{seed=None}}, \emph{\DUrole{n}{data\_manager=\{\textquotesingle{}force\_cpu\textquotesingle{}: False}}, \emph{\DUrole{n}{\textquotesingle{}remove\_mask\textquotesingle{}: False}}, \emph{\DUrole{n}{\textquotesingle{}state\textquotesingle{}: \textless{}\_StateMachine.CREATION: 0\textgreater{}}}, \emph{\DUrole{n}{\textquotesingle{}file\_name\_attack\textquotesingle{}: \textquotesingle{}file\_name\_attack.h5\textquotesingle{}}}, \emph{\DUrole{n}{\textquotesingle{}file\_name\_profiling\textquotesingle{}: None}}, \emph{\DUrole{n}{\textquotesingle{}databases\_path\textquotesingle{}: \textquotesingle{}/path/to/Databases/\textquotesingle{}}}, \emph{\DUrole{n}{\textquotesingle{}data\textquotesingle{}: None}}, \emph{\DUrole{n}{\textquotesingle{}has\_countermeasures\textquotesingle{}: False}}, \emph{\DUrole{n}{\textquotesingle{}\_poi\textquotesingle{}: None}}, \emph{\DUrole{n}{\textquotesingle{}na\textquotesingle{}: None}}, \emph{\DUrole{n}{\textquotesingle{}\_ns\textquotesingle{}: None}}, \emph{\DUrole{n}{\textquotesingle{}nt\textquotesingle{}: None}}, \emph{\DUrole{n}{\textquotesingle{}fs\textquotesingle{}: 0}}, \emph{\DUrole{n}{\textquotesingle{}blind\textquotesingle{}: False}}, \emph{\DUrole{n}{\textquotesingle{}check\_data\textquotesingle{}: (None}}, \emph{\DUrole{n}{None)}}, \emph{\DUrole{n}{\textquotesingle{}profiling\textquotesingle{}: True}}, \emph{\DUrole{n}{\textquotesingle{}device\textquotesingle{}: device(type=\textquotesingle{}cuda\textquotesingle{}}}, \emph{\DUrole{n}{index=1)\}}}, \emph{\DUrole{n}{results\_path=\textquotesingle{}/path/to/PlotsResults/\textquotesingle{}}}, \emph{\DUrole{n}{training=TrainingMethods.DEFAULT}}, \emph{\DUrole{n}{info=\textquotesingle{}\textquotesingle{}}}, \emph{\DUrole{n}{dim=1}}, \emph{\DUrole{n}{threshold=0.4}}, \emph{\DUrole{n}{LTH=0.8}}, \emph{\DUrole{n}{lr\_schedule=None}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Attack}}

\sphinxAtStartPar
Profiled attack class.

\sphinxAtStartPar
Profiled attacks use a profiling set acquired on a clone device on known key/ptx.
\index{\_\_init\_\_() (MLSCAlib.Attacks.profiled.Profiled method)@\spxentry{\_\_init\_\_()}\spxextra{MLSCAlib.Attacks.profiled.Profiled method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.profiled.Profiled.__init__}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{\emph{\DUrole{n}{epochs=15}}, \emph{\DUrole{n}{model\_name=\textquotesingle{}mlp\textquotesingle{}}}, \emph{\DUrole{n}{batch\_size=100}}, \emph{\DUrole{n}{loss=\textquotesingle{}nlll\textquotesingle{}}}, \emph{\DUrole{n}{optimizer=\textquotesingle{}Adam\textquotesingle{}}}, \emph{\DUrole{n}{leakage\_model=ID(SBox)}}, \emph{\DUrole{n}{verbose=1}}, \emph{\DUrole{n}{lambdas=None}}, \emph{\DUrole{n}{dk=False}}, \emph{\DUrole{n}{noise=False}}, \emph{\DUrole{n}{seed=None}}, \emph{\DUrole{n}{data\_manager=\{\textquotesingle{}force\_cpu\textquotesingle{}: False}}, \emph{\DUrole{n}{\textquotesingle{}remove\_mask\textquotesingle{}: False}}, \emph{\DUrole{n}{\textquotesingle{}state\textquotesingle{}: \textless{}\_StateMachine.CREATION: 0\textgreater{}}}, \emph{\DUrole{n}{\textquotesingle{}file\_name\_attack\textquotesingle{}: \textquotesingle{}file\_name\_attack.h5\textquotesingle{}}}, \emph{\DUrole{n}{\textquotesingle{}file\_name\_profiling\textquotesingle{}: None}}, \emph{\DUrole{n}{\textquotesingle{}databases\_path\textquotesingle{}: \textquotesingle{}/path/to/Databases/\textquotesingle{}}}, \emph{\DUrole{n}{\textquotesingle{}data\textquotesingle{}: None}}, \emph{\DUrole{n}{\textquotesingle{}has\_countermeasures\textquotesingle{}: False}}, \emph{\DUrole{n}{\textquotesingle{}\_poi\textquotesingle{}: None}}, \emph{\DUrole{n}{\textquotesingle{}na\textquotesingle{}: None}}, \emph{\DUrole{n}{\textquotesingle{}\_ns\textquotesingle{}: None}}, \emph{\DUrole{n}{\textquotesingle{}nt\textquotesingle{}: None}}, \emph{\DUrole{n}{\textquotesingle{}fs\textquotesingle{}: 0}}, \emph{\DUrole{n}{\textquotesingle{}blind\textquotesingle{}: False}}, \emph{\DUrole{n}{\textquotesingle{}check\_data\textquotesingle{}: (None}}, \emph{\DUrole{n}{None)}}, \emph{\DUrole{n}{\textquotesingle{}profiling\textquotesingle{}: True}}, \emph{\DUrole{n}{\textquotesingle{}device\textquotesingle{}: device(type=\textquotesingle{}cuda\textquotesingle{}}}, \emph{\DUrole{n}{index=1)\}}}, \emph{\DUrole{n}{results\_path=\textquotesingle{}/path/to/PlotsResults/\textquotesingle{}}}, \emph{\DUrole{n}{training=TrainingMethods.DEFAULT}}, \emph{\DUrole{n}{info=\textquotesingle{}\textquotesingle{}}}, \emph{\DUrole{n}{dim=1}}, \emph{\DUrole{n}{threshold=0.4}}, \emph{\DUrole{n}{LTH=0.8}}, \emph{\DUrole{n}{lr\_schedule=None}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Initializes an Attack.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{epochs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 15}}) \textendash{} how many epochs to train the NN.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{model\_name}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : mlp}}) \textendash{} Which NN model to use.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{batch\_size}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 100}}) \textendash{} Batch size used during training.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{loss}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : nlll}}) \textendash{} Loss function to use. Can be mse, cross\_entropy or nlll.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{optimizer}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : Adam}}) \textendash{} Can be Adam or SGD.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{leakage\_model}} (\sphinxstyleliteralemphasis{\sphinxupquote{Ciphers.LeakageModel}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : ID}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{SBox}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}) \textendash{} A LeakageModel class used for label computations.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1}}) \textendash{} What should be printed out during execution ? 0 : only the result,
1 : the different metrics (e.g. remaining time, sensitivities, accuracies),
2 : output debug informations too.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lambdas}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{Float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} If not None, specifies the L1 \& L2 regularization terms of two layers.
The first two values (by default 0.03,0.03) are the L1 and L2 regularization
for a model’s layer whose name is “regularized\_function\_1”. The next two values
are the L1 \& L2 regularization for any layer in the model whose name contain
“regularized\_function\_”.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dk}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to use Domain Knowledge neurons. Those add plaintext information
in the MLP part of the network.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{noise}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to add gaussian noise to the input of the training data.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{seed}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} Which seed to use. If set to None, will use a default standard value, 5437.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{data\_manager}} (\sphinxstyleliteralemphasis{\sphinxupquote{Data.DataManager}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : DataManager}}\sphinxstyleliteralemphasis{\sphinxupquote{(}}\sphinxstyleliteralemphasis{\sphinxupquote{)}}) \textendash{} The datamanager handles anything related to the data.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{results\_path}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : "/path/to/PlotsResults/"}}) \textendash{} Where to store the learning plots.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{training}} (\sphinxstyleliteralemphasis{\sphinxupquote{attacks.attack.TrainingMethods}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : Trainingmethods.DEFAULT}}) \textendash{} Which training method to use.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{info}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : ""}}) \textendash{} A small text to insert in the result file name.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dim}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 0}}) \textendash{} On which dimension/axis to apply the softmax filter in the NN.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{threshold}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 0.4}}) \textendash{} When the certainty is higher than this threshold, we assume the guess is correct.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{LTH}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 0.8}}) \textendash{} Percentage of the weights to mask in the LTH pruning. Only used if the training
method is set to TrainingMethods.PRUNING or TrainingMethods.PRUNING\_HALF\_EPOCHS.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{lr\_schedule}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{,}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]} }}\sphinxstyleliteralemphasis{\sphinxupquote{| }}\sphinxstyleliteralemphasis{\sphinxupquote{None. Default : None.}}) \textendash{} learning rate Scheduler parameter. If not None, after each lr\_schedule{[}0{]} epochs,
multiply the learning rate by lr\_schedule{[}1{]}.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{attack\_byte() (MLSCAlib.Attacks.profiled.Profiled method)@\spxentry{attack\_byte()}\spxextra{MLSCAlib.Attacks.profiled.Profiled method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.profiled.Profiled.attack_byte}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{attack\_byte}}}{\emph{\DUrole{n}{byte}}, \emph{\DUrole{n}{get\_output\_probas}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{split\_rate}\DUrole{o}{=}\DUrole{default_value}{0.95}}, \emph{\DUrole{n}{fast\_GE}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{get\_fast\_ge}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{fast\_sensi}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Attack byte: launches a full attack on a byte.

\sphinxAtStartPar
Will print the result of the attack on the terminal.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{byte}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} byte number to attack. Some bytes are harder to attack.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{get\_output\_probas}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to return the output probabilities of each 256 keys. If
the attack is blind, the function will return them anyway.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{split\_rate}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 0.95}}) \textendash{} In a blind attack scenario: which percentage of the profiling
traces to use for training. The rest will be used as a validation
set. In the other scenario, this is useless as the attack traces
will be used for validation and all the profiling traces for training.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fast\_GE}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to compute the fast Guessing Entropy at each epoch during
training.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{get\_fast\_ge}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to return the fast Guessing Entropy. (Note that even when set
to False, the GE may appear on the result pdf.)

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fast\_sensi}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to compute the value of the maximum peak of the sensitivity at
each epoch during training. Only returned if get\_fast\_ge is True.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
If the attack is blind, returns the key probabilities.
Otherwise, returns the Guessing entropy, the minimum amount of attack
traces needed to reach GE=1 if possible, the fast GEs and the sensitivity
peaks if demanded.

\sphinxlineitem{Return type}
\sphinxAtStartPar
res\_key\_probas | ge,min\_ge1,(fast\_GEs,fast\_sensis)

\end{description}\end{quote}

\end{fulllineitems}

\index{attack\_bytes() (MLSCAlib.Attacks.profiled.Profiled method)@\spxentry{attack\_bytes()}\spxextra{MLSCAlib.Attacks.profiled.Profiled method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.profiled.Profiled.attack_bytes}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{attack\_bytes}}}{\emph{\DUrole{n}{byte\_range}}, \emph{\DUrole{n}{get\_fast\_GE}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Launches the attack\_byte() method on each given byte in the byte\_range.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{byte\_range}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]} }}\sphinxstyleliteralemphasis{\sphinxupquote{| }}\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} On which byte(s) to launch a SCA.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{get\_fast\_GE}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} whether to compute \& return the fast Guessing Entropy over each epoch.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstylestrong{key\_ranking} (\sphinxstyleemphasis{List{[}int{]}}) \textendash{} The key ordered in decreased order of probability

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{key\_certainty} (\sphinxstyleemphasis{float}) \textendash{} An estimated probability that GE = 1.

\item {} 
\sphinxAtStartPar
\sphinxstylestrong{fast\_GEs} (\sphinxstyleemphasis{List{[}int{]} | None}) \textendash{} If get\_fast\_GE is True, the guessing entropy of each epoch.

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{get\_min\_trace\_for\_GE1() (MLSCAlib.Attacks.profiled.Profiled static method)@\spxentry{get\_min\_trace\_for\_GE1()}\spxextra{MLSCAlib.Attacks.profiled.Profiled static method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.profiled.Profiled.get_min_trace_for_GE1}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{static\DUrole{w}{  }}}\sphinxbfcode{\sphinxupquote{get\_min\_trace\_for\_GE1}}}{\emph{\DUrole{n}{output\_proba\_on\_key}}, \emph{\DUrole{n}{key\_byte}}, \emph{\DUrole{n}{step}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Computes the minimum number of traces required to get GE = 1.

\sphinxAtStartPar
Iteratively considers more and more attack traces until it is possible
to reach a Guessing Entropy of 1. You should consider taking the mean
over multiple execution to get a meaningfull result.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{output\_proba\_on\_key}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} List of probabilities sorted on the secret key for each plaintext.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{key\_byte}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} The value of the target key byte.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{step}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1}}) \textendash{} Defines by how much to increase the number of attack traces used until reaching GE=1
between each trial.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
Minimum amount of attack traces required to reach a Guessing Entropy of 1.

\sphinxlineitem{Return type}
\sphinxAtStartPar
int

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_pruning\_percentage() (MLSCAlib.Attacks.profiled.Profiled method)@\spxentry{get\_pruning\_percentage()}\spxextra{MLSCAlib.Attacks.profiled.Profiled method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.profiled.Profiled.get_pruning_percentage}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_pruning\_percentage}}}{}{}
\pysigstopsignatures
\end{fulllineitems}

\index{record\_attack() (MLSCAlib.Attacks.profiled.Profiled method)@\spxentry{record\_attack()}\spxextra{MLSCAlib.Attacks.profiled.Profiled method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.profiled.Profiled.record_attack}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{record\_attack}}}{\emph{\DUrole{n}{byte=3}}, \emph{\DUrole{n}{number\_of\_trials=10}}, \emph{\DUrole{n}{info\_for\_filename=\textquotesingle{}\textquotesingle{}}}, \emph{\DUrole{n}{info\_for\_plot=\textquotesingle{}\textquotesingle{}}}, \emph{\DUrole{n}{x\_axis=\textquotesingle{}epoch\textquotesingle{}}}, \emph{\DUrole{n}{redraw\_this=None}}, \emph{\DUrole{n}{legend\_location=\textquotesingle{}inside\textquotesingle{}}}, \emph{\DUrole{n}{display\_title=True}}, \emph{\DUrole{n}{target\_model\_substring=\textquotesingle{}\textquotesingle{}}}, \emph{\DUrole{n}{target\_model\_without\_substring=None}}, \emph{\DUrole{n}{ncols=1}}, \emph{\DUrole{n}{plot=False}}, \emph{\DUrole{n}{custom\_palette=None}}, \emph{\DUrole{n}{logit=False}}, \emph{\DUrole{n}{replace\_legend=\textless{}function Profiled.\textless{}lambda\textgreater{}\textgreater{}}}, \emph{\DUrole{n}{font\_size=10}}, \emph{\DUrole{n}{file\_extension=\textquotesingle{}pdf\textquotesingle{}}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Creates a graph that allows to compare the performance of different models.

\sphinxAtStartPar
The graph created will plot, for each model, the mean value of the Key Rank along with
a 95\% confidence interval. Each time this function is being executed, it will store the result in the
Results/ folder (inside the directory of this file). The naming of the temporary results (stored in a \sphinxstyleemphasis{.npy}) is
\sphinxstyleemphasis{\{info\_for\_filename\}\sphinxhyphen{}AXIS\sphinxhyphen{}\{x\_axis’\}\sphinxhyphen{}FAST\_GE\_epochs\sphinxhyphen{}\{self.epochs\},byte\sphinxhyphen{}\{byte\},\{self.data\_manager.get\_res\_name()\}.npy}.
Hence, when the user calls this function twice with the same \sphinxstyleemphasis{info\_for\_filename}, \sphinxstyleemphasis{x\_axis,epochs}, \sphinxstyleemphasis{byte} and the same
file (with na/ns/nt), it will combine the results into a same file. The graph will have a different line
for each model, where info\_for\_plot allows an additional model information addition. (i.e. using MLP with
“label : HW” will have a different line on the graph than MLP with “label : ID” as info\_for\_plot).
Warning: adding noise with CustomDataManager and using \sphinxstyleemphasis{number\_of\_trials = 0} will draw a graph with incorrect title.
Warning: Currently, the byte number should always stay the same between records of the same plot.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{byte}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default :3}}) \textendash{} Target byte number.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{number\_of\_trials}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 10}}) \textendash{} How many attack\_byte() runs to do. The graph will plot the mean + 95\% confidence interval.
If set to 0, it will generate the graph again, provided that the corresponding .npy file
is available in Results/ .

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{info\_for\_filename}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : ""}}) \textendash{} Determines a specific result\sphinxhyphen{}plot identifier. Each plot has a unique identifier. This means,
running this function multiple times with arguments leading to the same identifier will
result in a single plot (and different lines iff the model name / info\_for\_plot is different).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{info\_for\_plot}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : ""}}) \textendash{} When running this function, the Profiled class has a model name stored. This argument will add
a specific information in the legend of the graph alongside the model name. This for example
allows to have different lines for the same model but varying parameters.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{x\_axis}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : "epoch"}}) \textendash{} Along which x\sphinxhyphen{}axis to plot the graph. Can be either “na”, “nt”, “epoch” or “epoch\_sensi”. “na”\sphinxhyphen{}axis
will have thex\sphinxhyphen{}axis be the number of attack traces (hence the computation will incrementally change
the number of attack traces considered when doing the attack. na \textless{} 11, it will mean 100 trials. For
10\textless{}na\textless{}2400, it will mean 10 trials and otherwise just 1 trial. This is as such because to avoid pure
luck: using 1 (or few) attack trace may give the correct/wrong key just by luck.) Using “nt”\sphinxhyphen{}axis, the
x\sphinxhyphen{}axis will be along the number of profiling traces. For each index, the a whole computation is done with
the corresponding number of profiling traces (takes time). When using the “epoch”\sphinxhyphen{}axis, the x\sphinxhyphen{}axis
represents the number of epoch. This can be seen as a graph of fast\sphinxhyphen{}Guessing Entropy which uses
all of the validation traces instead of only a subset. When using “epoch\_sensi”, the function will produce
two pdf plots, each of them with epoch as x\sphinxhyphen{}axis. The first will have the key\sphinxhyphen{}rank as y\sphinxhyphen{}axis and the second
will have the highest sensitivity value for the given epoch.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{redraw\_this}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} Path to a .npy file containing the result of a previous recording that you wish to draw again without having
to give all the exact same parameters. The function will automatically infer the x\sphinxhyphen{}axis used.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{legend\_location}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : "inside"}}) \textendash{} Where to put the legend. Can be any of inside, bottom, upper left or absent.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{display\_title}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : True}}) \textendash{} Whether to put the title (name of the target set, number of traces, target byte) of the plot upon the plots.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{target\_model\_substring}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : ""}}) \textendash{} Only plots the models containing target\_model\_substring in their name.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{target\_model\_without\_substring}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} If not None (or “”), will only plot the models which do not contain target\_model\_without\_substring in
their name.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ncols}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1}}) \textendash{} On how many columns to spread the legend.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{plot}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default: False}}) \textendash{} Whether to plot the figure in addition to saving it in a pdf.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{custom\_palette}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} When given, will plot the epoch graph according to the given palette. It should be of size Mx3, where M
is the number of models remaining after the selection via target\_model\_substring and
target\_model\_without\_substring. Each have a color specified in RGB with 3 floats.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{logit}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default: False}}) \textendash{} Whether to plot the logit instead of the fast Guessing Entropy. The x\sphinxhyphen{}axis should be set to epoch.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{replace\_legend}} (\sphinxstyleliteralemphasis{\sphinxupquote{str \sphinxhyphen{}\textgreater{} str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default: lambda x:x}}) \textendash{} Function to change the legend element wise. For example, if the title of the plot is “MLP model with ID
labelling for different optimizers”, removing the “ID” or “MLP” mention in the labels may be useful.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{font\_size}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default: 10}}) \textendash{} The font size to use in the legend and axis.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{file\_extension}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default: "pdf"}}) \textendash{} The resulting file extension of the recording. Can be for example ‘png’, ‘pdf’, ‘svg’, ‘jpeg’, …

\end{itemize}

\sphinxlineitem{Raises}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{Error}} \textendash{} When number\_of\_trials is set to 0 and no previous trials have been done with the same arguments.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{Error}} \textendash{} When the target\_model\_(without)\_substring specification(s) disable(s) all the models. In that case, the names
    of all the available models will be printed in the console.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{train\_model\_adversarial() (MLSCAlib.Attacks.profiled.Profiled method)@\spxentry{train\_model\_adversarial()}\spxextra{MLSCAlib.Attacks.profiled.Profiled method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.profiled.Profiled.train_model_adversarial}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{train\_model\_adversarial}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Performs an adversarial learning. Not implemented yet.

\end{fulllineitems}

\index{train\_model\_cross\_validation() (MLSCAlib.Attacks.profiled.Profiled method)@\spxentry{train\_model\_cross\_validation()}\spxextra{MLSCAlib.Attacks.profiled.Profiled method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.profiled.Profiled.train_model_cross_validation}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{train\_model\_cross\_validation}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Performs a learning using cross\sphinxhyphen{}validation techniques. Not implemented yet.

\end{fulllineitems}

\index{train\_model\_default() (MLSCAlib.Attacks.profiled.Profiled method)@\spxentry{train\_model\_default()}\spxextra{MLSCAlib.Attacks.profiled.Profiled method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Attacks:MLSCAlib.Attacks.profiled.Profiled.train_model_default}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{train\_model\_default}}}{\emph{\DUrole{n}{x\_profiling}}, \emph{\DUrole{n}{label\_profiling}}, \emph{\DUrole{n}{x\_validation}}, \emph{\DUrole{n}{label\_validation}}, \emph{\DUrole{n}{plaintext\_val}}, \emph{\DUrole{n}{mask\_val}}, \emph{\DUrole{n}{key\_attack}}, \emph{\DUrole{n}{byte}}, \emph{\DUrole{n}{model}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{get\_metrics}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{fast}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{sensi\_reg}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{fast\_sensi}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Trains the model.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{x\_profiling}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}) \textendash{} The attack traces used for unprofiled training. Should have the shape (na,1,ns).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{label\_profiling}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} The labels corresponding to x\_attack.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{x\_validation}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}) \textendash{} Traces to use for metrics computations (e.g. sensitivity computation). Can be
the same as x\_attack.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{label\_validation}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} The labels corresponding to x\_attack\_val.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{List}}\sphinxstyleliteralstrong{\sphinxupquote{{[}}}\sphinxstyleliteralstrong{\sphinxupquote{int}}\sphinxstyleliteralstrong{\sphinxupquote{{]}}} (\sphinxstyleliteralemphasis{\sphinxupquote{plaintext\_val ;}}) \textendash{} The plaintexts corresponding to x\_validation

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{key\_attack}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} The attack key(s).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{byte}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Target byte index.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{model}} (\sphinxstyleliteralemphasis{\sphinxupquote{nn.Module}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} If not set to None, will re\sphinxhyphen{}use the model given instaed of creating a new.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{get\_metrics}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : True}}) \textendash{} Whether to calculate validation accuracy and training accuracy.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fast}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : True}}) \textendash{} Whether to calculate the fast Guessing Entropy during learning. May induce
additionnal delays.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{sensi\_reg}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to apply a sensitivity regularization. This is not implemented yet
for profiled attacks.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fast\_sensi}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to return, for each epoch, the value of the highest sensitivity peak
computed on the vlidation data.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{model} \textendash{} The trained model.

\sphinxlineitem{Return type}
\sphinxAtStartPar
torch.nn.Module

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}


\sphinxstepscope


\subsubsection{MLSCAlib.Ciphers package}
\label{\detokenize{MLSCAlib.Ciphers:mlscalib-ciphers-package}}\label{\detokenize{MLSCAlib.Ciphers::doc}}

\paragraph{Submodules}
\label{\detokenize{MLSCAlib.Ciphers:submodules}}

\paragraph{MLSCAlib.Ciphers.AES\_leakage module}
\label{\detokenize{MLSCAlib.Ciphers:module-MLSCAlib.Ciphers.AES_leakage}}\label{\detokenize{MLSCAlib.Ciphers:mlscalib-ciphers-aes-leakage-module}}\index{module@\spxentry{module}!MLSCAlib.Ciphers.AES\_leakage@\spxentry{MLSCAlib.Ciphers.AES\_leakage}}\index{MLSCAlib.Ciphers.AES\_leakage@\spxentry{MLSCAlib.Ciphers.AES\_leakage}!module@\spxentry{module}}\index{AESLeakageModel (class in MLSCAlib.Ciphers.AES\_leakage)@\spxentry{AESLeakageModel}\spxextra{class in MLSCAlib.Ciphers.AES\_leakage}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.AES_leakage.AESLeakageModel}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Ciphers.AES\_leakage.}}\sphinxbfcode{\sphinxupquote{AESLeakageModel}}}{\emph{\DUrole{n}{leakage\_model}}, \emph{\DUrole{n}{leakage\_location}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}SBox\textquotesingle{}}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{LeakageModel}}

\sphinxAtStartPar
\sphinxstylestrong{AES} (\sphinxstylestrong{ECB}) Leakage Model class. Encapsulates all the tools necessary to recover the labels of the attack.
\index{\_\_init\_\_() (MLSCAlib.Ciphers.AES\_leakage.AESLeakageModel method)@\spxentry{\_\_init\_\_()}\spxextra{MLSCAlib.Ciphers.AES\_leakage.AESLeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.AES_leakage.AESLeakageModel.__init__}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{\emph{\DUrole{n}{leakage\_model}}, \emph{\DUrole{n}{leakage\_location}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}SBox\textquotesingle{}}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Instantiates the \sphinxstylestrong{AES} Leakage Model.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{leakage\_model}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Which leakage labelling to use. Can be \sphinxstylestrong{ID}, \sphinxstylestrong{HW}, \sphinxstylestrong{LSBS}, \sphinxstylestrong{LSB}, \sphinxstylestrong{MSB} or \sphinxstylestrong{HW2}.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{leakage\_location}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} Targetted \sphinxstylestrong{AES} function. May be \sphinxstyleemphasis{AddRoundKey}, \sphinxstyleemphasis{SBox}, \sphinxstyleemphasis{LastSBox}, or \sphinxstyleemphasis{key}.
The LastSBox labelling is only possible when ciphertext information is
available.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{check\_key() (MLSCAlib.Ciphers.AES\_leakage.AESLeakageModel method)@\spxentry{check\_key()}\spxextra{MLSCAlib.Ciphers.AES\_leakage.AESLeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.AES_leakage.AESLeakageModel.check_key}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{check\_key}}}{\emph{\DUrole{n}{plaintext}}, \emph{\DUrole{n}{ciphertext}}, \emph{\DUrole{n}{key}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Checks if the key given is correct.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{plaintext}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} A plaintext.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ciphertext}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} A ciphertext corresponding to the plaintext.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{key}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} A guessed key.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{Returns}} \textendash{} 

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bool}} \textendash{} Whether the given key is correct.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_imbalanced\_classes() (MLSCAlib.Ciphers.AES\_leakage.AESLeakageModel method)@\spxentry{get\_imbalanced\_classes()}\spxextra{MLSCAlib.Ciphers.AES\_leakage.AESLeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.AES_leakage.AESLeakageModel.get_imbalanced_classes}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_imbalanced\_classes}}}{}{}
\pysigstopsignatures
\end{fulllineitems}

\index{get\_labelled\_output() (MLSCAlib.Ciphers.AES\_leakage.AESLeakageModel method)@\spxentry{get\_labelled\_output()}\spxextra{MLSCAlib.Ciphers.AES\_leakage.AESLeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.AES_leakage.AESLeakageModel.get_labelled_output}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_labelled\_output}}}{\emph{\DUrole{n}{ptx\_i}}, \emph{\DUrole{n}{key\_i}}, \emph{\DUrole{n}{mask\_i}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{byte\_position}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Get labelled output: given a subset of the plaintext and a subset of the key,
recover the labelled output of the leakage location.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ptx\_i}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} i\sphinxhyphen{}th byte of a plaintext.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{key\_i}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} i\sphinxhyphen{}th byte of a key.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mask\_i}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} i\sphinxhyphen{}th byte of the mask.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
Label of the output of the target function with given inputs.

\sphinxlineitem{Return type}
\sphinxAtStartPar
int

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_snr\_poi() (MLSCAlib.Ciphers.AES\_leakage.AESLeakageModel method)@\spxentry{get\_snr\_poi()}\spxextra{MLSCAlib.Ciphers.AES\_leakage.AESLeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.AES_leakage.AESLeakageModel.get_snr_poi}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_snr\_poi}}}{\emph{\DUrole{n}{traces\_waves}}, \emph{\DUrole{n}{plaintexts}}, \emph{\DUrole{n}{keys}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Calculates the position of the highest SNR peak if no countermeasures are implemented.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{traces\_waves}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}) \textendash{} The list of profiling traces.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{plaintexts}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}) \textendash{} The list of plaintexts.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{keys}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}) \textendash{} The list of keys

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
The location of the mean of the highest SNR peaks over each byte.

\sphinxlineitem{Return type}
\sphinxAtStartPar
int

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_used\_keys() (MLSCAlib.Ciphers.AES\_leakage.AESLeakageModel method)@\spxentry{get\_used\_keys()}\spxextra{MLSCAlib.Ciphers.AES\_leakage.AESLeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.AES_leakage.AESLeakageModel.get_used_keys}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_used\_keys}}}{\emph{\DUrole{n}{keys}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Get the key used in the labelling.

\sphinxAtStartPar
Usually, a cipher may produce round keys. Depending on the targetted
sub\sphinxhyphen{}function (if the target is the LastSBox), the labelling may depend
on a round key instead of the  plain private key. This function returns
the corresponding round key or the plain key depending on the leakage model.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{keys}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} List of the keys.

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{round\_keys} \textendash{} Round keys.

\sphinxlineitem{Return type}
\sphinxAtStartPar
List{[}List{[}int{]}{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{needs\_cipher\_and\_not\_ptx() (MLSCAlib.Ciphers.AES\_leakage.AESLeakageModel method)@\spxentry{needs\_cipher\_and\_not\_ptx()}\spxextra{MLSCAlib.Ciphers.AES\_leakage.AESLeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.AES_leakage.AESLeakageModel.needs_cipher_and_not_ptx}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{needs\_cipher\_and\_not\_ptx}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
To know whether the LeakageModel needs the ciphertext instead of the plaintext.

\end{fulllineitems}

\index{recover\_input() (MLSCAlib.Ciphers.AES\_leakage.AESLeakageModel method)@\spxentry{recover\_input()}\spxextra{MLSCAlib.Ciphers.AES\_leakage.AESLeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.AES_leakage.AESLeakageModel.recover_input}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{recover\_input}}}{\emph{\DUrole{n}{label\_i}}, \emph{\DUrole{n}{ptx\_i}}, \emph{\DUrole{n}{byte\_position}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{mask\_i}\DUrole{o}{=}\DUrole{default_value}{0}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Recover input: given a label and a subset of the plaintext,
recover the possible key(s) leading to the label.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{label\_i}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} the label corresponding to the ptx\_i and a key.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ptx\_i}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} i\sphinxhyphen{}th byte of a plaintext.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mask\_i}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 0}}) \textendash{} i\sphinxhyphen{}th byte of the mask.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
In case of a ID labelling, returns the possible key leading to the given label.
Otherwise, returns a list with all possible keys leading to that label.

\sphinxlineitem{Return type}
\sphinxAtStartPar
int,List{[}int{]}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}



\paragraph{MLSCAlib.Ciphers.leakage\_model module}
\label{\detokenize{MLSCAlib.Ciphers:module-MLSCAlib.Ciphers.leakage_model}}\label{\detokenize{MLSCAlib.Ciphers:mlscalib-ciphers-leakage-model-module}}\index{module@\spxentry{module}!MLSCAlib.Ciphers.leakage\_model@\spxentry{MLSCAlib.Ciphers.leakage\_model}}\index{MLSCAlib.Ciphers.leakage\_model@\spxentry{MLSCAlib.Ciphers.leakage\_model}!module@\spxentry{module}}\index{LeakageModel (class in MLSCAlib.Ciphers.leakage\_model)@\spxentry{LeakageModel}\spxextra{class in MLSCAlib.Ciphers.leakage\_model}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Ciphers.leakage\_model.}}\sphinxbfcode{\sphinxupquote{LeakageModel}}}{\emph{\DUrole{n}{leakage\_model}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{ABC}}

\sphinxAtStartPar
Base class for leakage modelling. Each instantiation should be tailored to a specific cipher.
\index{\_\_init\_\_() (MLSCAlib.Ciphers.leakage\_model.LeakageModel method)@\spxentry{\_\_init\_\_()}\spxextra{MLSCAlib.Ciphers.leakage\_model.LeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel.__init__}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{\emph{\DUrole{n}{leakage\_model}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Instantiates the class.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{leakage\_model}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} which leakage labelling to use. Can be ID,HW,LSBS,LSB,MSB, HW2 or HW3.

\sphinxlineitem{Raises}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{Error}} \textendash{} when an unimplemented leakage labelling is given.

\end{description}\end{quote}

\end{fulllineitems}

\index{check\_key() (MLSCAlib.Ciphers.leakage\_model.LeakageModel method)@\spxentry{check\_key()}\spxextra{MLSCAlib.Ciphers.leakage\_model.LeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel.check_key}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{abstract\DUrole{w}{  }}}\sphinxbfcode{\sphinxupquote{check\_key}}}{\emph{\DUrole{n}{plaintext}}, \emph{\DUrole{n}{ciphertext}}, \emph{\DUrole{n}{key}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Checks if the key given is correct.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{plaintext}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} A plaintext.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ciphertext}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} A ciphertext corresponding to the plaintext.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{key}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} A guessed key.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{Returns}} \textendash{} 

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{bool}} \textendash{} Whether the given key is correct.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_class\_balance() (MLSCAlib.Ciphers.leakage\_model.LeakageModel method)@\spxentry{get\_class\_balance()}\spxextra{MLSCAlib.Ciphers.leakage\_model.LeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel.get_class_balance}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_class\_balance}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Could return a 1D Tensor of weights to counter class imbalance.

\sphinxAtStartPar
Since it doesn’t work well (see Picek \sphinxstyleemphasis{et al.}%
\begin{footnote}[1]\sphinxAtStartFootnote
Stjepan Picek, Annelie Heuser, Alan Jovic, Shivam Bhasin, and Francesco Regazzoni. The Curse of Class Imbalance and Conflicting Metrics with Machine Learning for Side\sphinxhyphen{}channel Evaluations. \sphinxstyleemphasis{IACR Transactions on Cryptographic Hardware and Embedded Systems}, 2019(1):1\textendash{}29, August 2019. URL: \sphinxurl{https://hal.inria.fr/hal-01935318}, \sphinxhref{https://doi.org/10.13154/tches.v2019.i1.209-237}{doi:10.13154/tches.v2019.i1.209\sphinxhyphen{}237}.
%
\end{footnote}), it is disabled and set to always return
a balanced distribution. One should use SMOTE instead (see Chawla \sphinxstyleemphasis{et al.}%
\begin{footnote}[2]\sphinxAtStartFootnote
Nitesh V Chawla, Kevin W Bowyer, Lawrence O Hall, and W Philip Kegelmeyer. Smote: synthetic minority over\sphinxhyphen{}sampling technique. \sphinxstyleemphasis{Journal of artificial intelligence research}, 16:321\textendash{}357, 2002.
%
\end{footnote}).

\end{fulllineitems}

\index{get\_classes() (MLSCAlib.Ciphers.leakage\_model.LeakageModel method)@\spxentry{get\_classes()}\spxextra{MLSCAlib.Ciphers.leakage\_model.LeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel.get_classes}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_classes}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Returns the number of classes corresponding to the labelling.

\end{fulllineitems}

\index{get\_imbalanced\_classes() (MLSCAlib.Ciphers.leakage\_model.LeakageModel method)@\spxentry{get\_imbalanced\_classes()}\spxextra{MLSCAlib.Ciphers.leakage\_model.LeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel.get_imbalanced_classes}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_imbalanced\_classes}}}{}{}
\pysigstopsignatures
\end{fulllineitems}

\index{get\_labelled\_output() (MLSCAlib.Ciphers.leakage\_model.LeakageModel method)@\spxentry{get\_labelled\_output()}\spxextra{MLSCAlib.Ciphers.leakage\_model.LeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel.get_labelled_output}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{abstract\DUrole{w}{  }}}\sphinxbfcode{\sphinxupquote{get\_labelled\_output}}}{\emph{\DUrole{n}{ptx\_i}}, \emph{\DUrole{n}{key\_i}}, \emph{\DUrole{n}{mask\_i}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{byte\_position}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Get labelled output: given a subset of the plaintext and a subset of the key,
recover the labelled output of the leakage location.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ptx\_i}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} i\sphinxhyphen{}th byte of a plaintext.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{key\_i}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} i\sphinxhyphen{}th byte of a key.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mask\_i}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} i\sphinxhyphen{}th byte of the mask.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
label of the output of the target function with given inputs.

\sphinxlineitem{Return type}
\sphinxAtStartPar
int

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_same\_label\_values() (MLSCAlib.Ciphers.leakage\_model.LeakageModel method)@\spxentry{get\_same\_label\_values()}\spxextra{MLSCAlib.Ciphers.leakage\_model.LeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel.get_same_label_values}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_same\_label\_values}}}{\emph{\DUrole{n}{guessed\_label}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Returns the list of different values leading to the given guessed label.

\end{fulllineitems}

\index{get\_small\_profiling\_labels() (MLSCAlib.Ciphers.leakage\_model.LeakageModel method)@\spxentry{get\_small\_profiling\_labels()}\spxextra{MLSCAlib.Ciphers.leakage\_model.LeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel.get_small_profiling_labels}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_small\_profiling\_labels}}}{\emph{\DUrole{n}{plaintext}}, \emph{\DUrole{n}{byte\_position}}, \emph{\DUrole{n}{keys}}, \emph{\DUrole{n}{profiling}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{mask}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Returns a list of the corresponding label.

\sphinxAtStartPar
Computed for example as label = HW(SBox(plaintext{[}i{]}{[}byte\_pos{]} XOR keys{[}i{]}) XOR mask{[}i{]}{[}byte\_pos{]}), for i in {[}0,255{]}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{plaintext}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} list of plaintexts.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{byte}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} target byte number.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{keys}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{,}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} For non\sphinxhyphen{}profiling attacks: an int \textless{}16 representing a guess for the key byte at position byte.
For Profiling attacks: the list of profiling keys.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mask}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} List of masks used. If none, will not xor the target function’s output with masks.
Should be of the same shape than the plaintext.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
list of labels computed as label = Label(output of target function) for each ptx/key pair.

\sphinxlineitem{Return type}
\sphinxAtStartPar
List{[}int{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_snr\_poi() (MLSCAlib.Ciphers.leakage\_model.LeakageModel method)@\spxentry{get\_snr\_poi()}\spxextra{MLSCAlib.Ciphers.leakage\_model.LeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel.get_snr_poi}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{abstract\DUrole{w}{  }}}\sphinxbfcode{\sphinxupquote{get\_snr\_poi}}}{\emph{\DUrole{n}{traces\_waves}}, \emph{\DUrole{n}{plaintexts}}, \emph{\DUrole{n}{keys}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Calculates the position of the highest SNR peak if no countermeasures are implemented.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{traces\_waves}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}) \textendash{} The list of profiling traces.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{plaintexts}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}) \textendash{} The list of plaintexts.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{keys}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}) \textendash{} The list of keys

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
The location of the mean of the highest SNR peaks over each byte.

\sphinxlineitem{Return type}
\sphinxAtStartPar
int

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_type() (MLSCAlib.Ciphers.leakage\_model.LeakageModel method)@\spxentry{get\_type()}\spxextra{MLSCAlib.Ciphers.leakage\_model.LeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel.get_type}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_type}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Returns the leakage labelling.

\end{fulllineitems}

\index{get\_used\_keys() (MLSCAlib.Ciphers.leakage\_model.LeakageModel method)@\spxentry{get\_used\_keys()}\spxextra{MLSCAlib.Ciphers.leakage\_model.LeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel.get_used_keys}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{abstract\DUrole{w}{  }}}\sphinxbfcode{\sphinxupquote{get\_used\_keys}}}{\emph{\DUrole{n}{keys}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Get the key used in the labelling.

\sphinxAtStartPar
Usually, a cipher may produce round keys. Depending on the targetted
sub\sphinxhyphen{}function, the labelling may depend on a round key instead of the
plain private key. This function returns the corresponding round key
or the plain key depending on the leakage model.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{keys}} (\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} List of the keys.

\sphinxlineitem{Returns}
\sphinxAtStartPar
\sphinxstylestrong{round\_keys} \textendash{} Round keys.

\sphinxlineitem{Return type}
\sphinxAtStartPar
List{[}List{[}int{]}{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{is\_ID() (MLSCAlib.Ciphers.leakage\_model.LeakageModel method)@\spxentry{is\_ID()}\spxextra{MLSCAlib.Ciphers.leakage\_model.LeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel.is_ID}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{is\_ID}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Returns True iff the labelling is the identity.

\end{fulllineitems}

\index{is\_balanced() (MLSCAlib.Ciphers.leakage\_model.LeakageModel method)@\spxentry{is\_balanced()}\spxextra{MLSCAlib.Ciphers.leakage\_model.LeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel.is_balanced}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{is\_balanced}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Returns whether the labeling is balanced.

\end{fulllineitems}

\index{label() (MLSCAlib.Ciphers.leakage\_model.LeakageModel method)@\spxentry{label()}\spxextra{MLSCAlib.Ciphers.leakage\_model.LeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel.label}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{label}}}{\emph{\DUrole{n}{output}}, \emph{\DUrole{n}{before\_output}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{needs\_cipher\_and\_not\_ptx() (MLSCAlib.Ciphers.leakage\_model.LeakageModel method)@\spxentry{needs\_cipher\_and\_not\_ptx()}\spxextra{MLSCAlib.Ciphers.leakage\_model.LeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel.needs_cipher_and_not_ptx}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{abstract\DUrole{w}{  }}}\sphinxbfcode{\sphinxupquote{needs\_cipher\_and\_not\_ptx}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
To know whether the LeakageModel needs the ciphertext instead of the plaintext.

\end{fulllineitems}

\index{recover\_input() (MLSCAlib.Ciphers.leakage\_model.LeakageModel method)@\spxentry{recover\_input()}\spxextra{MLSCAlib.Ciphers.leakage\_model.LeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel.recover_input}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{abstract\DUrole{w}{  }}}\sphinxbfcode{\sphinxupquote{recover\_input}}}{\emph{\DUrole{n}{label\_i}}, \emph{\DUrole{n}{ptx\_i}}, \emph{\DUrole{n}{byte\_position}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{mask\_i}\DUrole{o}{=}\DUrole{default_value}{0}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Recover input: given a label and a subset of the plaintext,
recover the possible key(s) leading to the label.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{label\_i}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} the label corresponding to the ptx\_i and a key.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ptx\_i}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} i\sphinxhyphen{}th byte of a plaintext.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{mask\_i}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 0}}) \textendash{} i\sphinxhyphen{}th byte of the mask.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
In case of a ID labelling, returns the possible key leading to the gien label.
Otherwise, returns a list with all possible keys leading to that label.

\sphinxlineitem{Return type}
\sphinxAtStartPar
int,List{[}int{]}

\end{description}\end{quote}

\end{fulllineitems}

\index{recover\_key\_byte\_hypothesis() (MLSCAlib.Ciphers.leakage\_model.LeakageModel method)@\spxentry{recover\_key\_byte\_hypothesis()}\spxextra{MLSCAlib.Ciphers.leakage\_model.LeakageModel method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel.recover_key_byte_hypothesis}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{recover\_key\_byte\_hypothesis}}}{\emph{\DUrole{n}{plaintext\_i}}, \emph{\DUrole{n}{byte\_position}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{mask\_i}\DUrole{o}{=}\DUrole{default_value}{0}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Returns the most key byte related to the guessed label.
\begin{description}
\sphinxlineitem{plaintext\_i}{[}int{]}
\sphinxAtStartPar
a plaintext byte.

\end{description}
\begin{quote}\begin{description}
\sphinxlineitem{Returns}
\sphinxAtStartPar
list with likelihood for each key

\sphinxlineitem{Return type}
\sphinxAtStartPar
List{[}int{]}

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}


\sphinxstepscope


\subsubsection{MLSCAlib.Data package}
\label{\detokenize{MLSCAlib.Data:mlscalib-data-package}}\label{\detokenize{MLSCAlib.Data::doc}}

\paragraph{Submodules}
\label{\detokenize{MLSCAlib.Data:submodules}}

\paragraph{MLSCAlib.Data.chipwhisperer\_converter module}
\label{\detokenize{MLSCAlib.Data:module-MLSCAlib.Data.chipwhisperer_converter}}\label{\detokenize{MLSCAlib.Data:mlscalib-data-chipwhisperer-converter-module}}\index{module@\spxentry{module}!MLSCAlib.Data.chipwhisperer\_converter@\spxentry{MLSCAlib.Data.chipwhisperer\_converter}}\index{MLSCAlib.Data.chipwhisperer\_converter@\spxentry{MLSCAlib.Data.chipwhisperer\_converter}!module@\spxentry{module}}\index{MockProj (class in MLSCAlib.Data.chipwhisperer\_converter)@\spxentry{MockProj}\spxextra{class in MLSCAlib.Data.chipwhisperer\_converter}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.chipwhisperer_converter.MockProj}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Data.chipwhisperer\_converter.}}\sphinxbfcode{\sphinxupquote{MockProj}}}{\emph{\DUrole{n}{pickle\_path\_file}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{object}}

\end{fulllineitems}

\index{MockProj2 (class in MLSCAlib.Data.chipwhisperer\_converter)@\spxentry{MockProj2}\spxextra{class in MLSCAlib.Data.chipwhisperer\_converter}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.chipwhisperer_converter.MockProj2}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Data.chipwhisperer\_converter.}}\sphinxbfcode{\sphinxupquote{MockProj2}}}{\emph{\DUrole{n}{traces}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{object}}

\end{fulllineitems}

\index{save\_chip\_trace\_to\_h5() (in module MLSCAlib.Data.chipwhisperer\_converter)@\spxentry{save\_chip\_trace\_to\_h5()}\spxextra{in module MLSCAlib.Data.chipwhisperer\_converter}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.chipwhisperer_converter.save_chip_trace_to_h5}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{MLSCAlib.Data.chipwhisperer\_converter.}}\sphinxbfcode{\sphinxupquote{save\_chip\_trace\_to\_h5}}}{\emph{\DUrole{n}{proj}}, \emph{\DUrole{n}{nt}}, \emph{\DUrole{n}{na}}, \emph{\DUrole{n}{ns}\DUrole{o}{=}\DUrole{default_value}{14000}}, \emph{\DUrole{n}{fs}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{info}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}\textquotesingle{}}}, \emph{\DUrole{n}{datasets\_root\_folder}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}/path/to/Databases/\textquotesingle{}}}, \emph{\DUrole{n}{profiling\_key\_type}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}fresh\textquotesingle{}}}, \emph{\DUrole{n}{scale}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{ceiling}\DUrole{o}{=}\DUrole{default_value}{True}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Saves a chipwhisperer’s project traces in a .h5 file.

\sphinxAtStartPar
The chipwhisperer’s project traces have to contain nt profiling traces followed by na attack traces.
The operation is done incrementally to avoid high CPU/RAM usage.
Output file structure:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{{[}Profiling\_traces/traces{]}}

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{{[}Profiling\_traces/metadata{]}{[}plaintext{]}}

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{{[}Profiling\_traces/metadata{]}{[}key{]}}

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{{[}Profiling\_traces/metadata{]}{[}ciphertext{]}} (if exists)

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{{[}Attack\_traces/traces{]}}

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{{[}Attack\_traces/metadata{]}{[}plaintext{]}}

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{{[}Attack\_traces/metadata{]}{[}key{]}} (if exists)

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{{[}Attack\_traces/metadata{]}{[}ciphertext{]}} (if exists)

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{{[}Profiling\_traces/metadata{]}{[}masks{]}} (if exists)

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{{[}Profiling\_traces/metadata{]}{[}masks{]}} (if exists)

\end{itemize}
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{proj}} (\sphinxstyleliteralemphasis{\sphinxupquote{chipwhisperer.Project}}) \textendash{} The project.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{nt}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of profiling traces.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{na}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Number of attack traces.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ns}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 14000}}) \textendash{} Number of samples per trace.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 0}}) \textendash{} Offset, index of first sample in each trace to consider.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{info}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : ""}}) \textendash{} Information string to add to the file.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{datasets\_root\_folder}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : "/path/to/Databases/"}}) \textendash{} The path where to save the data.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{profiling\_key\_type}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : fresh}}) \textendash{} Can be for example fresh or fixed. To be used in the filename description. Asserts whether the profiling
traces use random(fresh) or a fixed key(s) for each Trace.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{scale}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} Whether to multiply each measurements by 100.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ceiling}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : True}}) \textendash{} Whether to ceil the result to an integer.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}



\paragraph{MLSCAlib.Data.data\_manager module}
\label{\detokenize{MLSCAlib.Data:module-MLSCAlib.Data.data_manager}}\label{\detokenize{MLSCAlib.Data:mlscalib-data-data-manager-module}}\index{module@\spxentry{module}!MLSCAlib.Data.data\_manager@\spxentry{MLSCAlib.Data.data\_manager}}\index{MLSCAlib.Data.data\_manager@\spxentry{MLSCAlib.Data.data\_manager}!module@\spxentry{module}}\index{DataManager (class in MLSCAlib.Data.data\_manager)@\spxentry{DataManager}\spxextra{class in MLSCAlib.Data.data\_manager}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.data_manager.DataManager}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Data.data\_manager.}}\sphinxbfcode{\sphinxupquote{DataManager}}}{\emph{\DUrole{n}{na}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}all\textquotesingle{}}}, \emph{\DUrole{n}{ns}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}all\textquotesingle{}}}, \emph{\DUrole{n}{nt}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}all\textquotesingle{}}}, \emph{\DUrole{n}{fs}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{file\_name\_attack}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}file\_name\_attack.h5\textquotesingle{}}}, \emph{\DUrole{n}{file\_name\_profiling}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{databases\_path}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}/path/to/Databases/\textquotesingle{}}}, \emph{\DUrole{n}{has\_countermeasures}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{blind}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{force\_cpu}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{remove\_mask}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{object}}

\sphinxAtStartPar
DataManager : handles anything needed for the data.

\sphinxAtStartPar
Prepares the attack dataset upon creation and computes the labels on demand.
You should not change the leakage model on the fly.
\index{\_\_init\_\_() (MLSCAlib.Data.data\_manager.DataManager method)@\spxentry{\_\_init\_\_()}\spxextra{MLSCAlib.Data.data\_manager.DataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.data_manager.DataManager.__init__}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{\emph{\DUrole{n}{na}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}all\textquotesingle{}}}, \emph{\DUrole{n}{ns}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}all\textquotesingle{}}}, \emph{\DUrole{n}{nt}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}all\textquotesingle{}}}, \emph{\DUrole{n}{fs}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{file\_name\_attack}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}file\_name\_attack.h5\textquotesingle{}}}, \emph{\DUrole{n}{file\_name\_profiling}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{databases\_path}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}/path/to/Databases/\textquotesingle{}}}, \emph{\DUrole{n}{has\_countermeasures}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{blind}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{force\_cpu}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{remove\_mask}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Initializes the DataManager.

\sphinxAtStartPar
Does also basic attack preprocessing, such as data standardization/centering, data shuffling and,
if no countermeasures are used, compute the Point of Interest of the data and makes sure the
resulting traces contain the PoI.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{na}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} How many attack traces to use.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ns}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} How many samples per trace to use.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{nt}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} How many profiling traces to use.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 0}}) \textendash{} First sample to use in each trace. Acts like an offset.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{file\_name\_attack}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} The file name containing the attack (and optionally Profiling traces if file\_name\_profiling is not None)
traces and the metadata in .h5 format.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{file\_name\_profiling}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} If given, will use the profiling traces in this file (and the attack traces from file file\_name\_attack).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{databases\_path}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : "/path/to/Databases/"}}) \textendash{} The directory of the target file.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{has\_countermeasures}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether the underlying data was generated using counteremasures.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{blind}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} When the dataset does not contain the attack key(s), the blind attribute will automatically be set to True.
In case there is an attack key information available, setting blind to True will discard this information.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{force\_cpu}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} If true, won’t use the GPU’s even if available.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{remove\_mask}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} In case of a masked implementation, will remove the mask from the data if given in the dataset .h5 file.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_check\_data() (MLSCAlib.Data.data\_manager.DataManager method)@\spxentry{get\_check\_data()}\spxextra{MLSCAlib.Data.data\_manager.DataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.data_manager.DataManager.get_check_data}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_check\_data}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
This function returns a plaintext/ciphertext pair that can further be used to test a key.

\end{fulllineitems}

\index{get\_ns() (MLSCAlib.Data.data\_manager.DataManager method)@\spxentry{get\_ns()}\spxextra{MLSCAlib.Data.data\_manager.DataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.data_manager.DataManager.get_ns}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_ns}}}{\emph{\DUrole{n}{leakage\_model}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Returns the number of sample per trace.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{leakage\_model}} ({\hyperref[\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel}]{\sphinxcrossref{\sphinxstyleliteralemphasis{\sphinxupquote{LeakageModel}}}}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} If the DataManager has not been fully initialized, it need a
leakage model in order to compute the number of samples. O/W,
you can ommit it.

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_res\_name() (MLSCAlib.Data.data\_manager.DataManager method)@\spxentry{get\_res\_name()}\spxextra{MLSCAlib.Data.data\_manager.DataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.data_manager.DataManager.get_res_name}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_res\_name}}}{\emph{\DUrole{n}{leakage\_model}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Returns a string describing the DataManager attributes.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{leakage\_model}} ({\hyperref[\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel}]{\sphinxcrossref{\sphinxstyleliteralemphasis{\sphinxupquote{LeakageModel}}}}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} If the DataManager has not been fully initialized, it need a
leakage model in order to compute the res name. O/W,
you can ommit it.

\end{description}\end{quote}

\end{fulllineitems}

\index{ns (MLSCAlib.Data.data\_manager.DataManager property)@\spxentry{ns}\spxextra{MLSCAlib.Data.data\_manager.DataManager property}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.data_manager.DataManager.ns}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{property\DUrole{w}{  }}}\sphinxbfcode{\sphinxupquote{ns}}}
\pysigstopsignatures
\end{fulllineitems}

\index{prepare\_profiled\_data() (MLSCAlib.Data.data\_manager.DataManager method)@\spxentry{prepare\_profiled\_data()}\spxextra{MLSCAlib.Data.data\_manager.DataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.data_manager.DataManager.prepare_profiled_data}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{prepare\_profiled\_data}}}{\emph{\DUrole{n}{byte}}, \emph{\DUrole{n}{leakage\_model}}, \emph{\DUrole{n}{use\_attack\_as\_val}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{split\_rate}\DUrole{o}{=}\DUrole{default_value}{0.95}}, \emph{\DUrole{n}{dk}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Prepares the data for profiled attacks.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{byte}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} The target byte index.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{leakage\_model}} ({\hyperref[\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel}]{\sphinxcrossref{\sphinxstyleliteralemphasis{\sphinxupquote{LeakageModel}}}}}) \textendash{} The underlying LeakageModel used for label computation.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{use\_attack\_as\_val}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} Whether to use the attack traces as validation set. If set to False, will split the profiling traces
in training/validation. If set to None, will use the attack traces as validation only if the
attack is not blind.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{split\_rate}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 0.95}}) \textendash{} In case use\_attack\_as\_val is set to False, will split the profiling traces in training/validation
traces according to split\_rate ratio.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dk}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} Whether to use Domain Knowledge neurons.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}float{]}{]}} \textendash{} Traces to use for training.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} Labels of the training traces.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}float{]}{]}} \textendash{} Traces used for validation. May be the same as the attack traces.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} Labels corresponding to the validation traces.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} Plaintexts corresponding to the validation traces.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}float{]}{]}} \textendash{} Attack traces

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} It is the labels of the attack traces, computed with the key\_guess.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} Plaintexts corresponding to the attack traces.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} List of the attack keys (na times the same key in a list).

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{prepare\_unprofiled\_data() (MLSCAlib.Data.data\_manager.DataManager method)@\spxentry{prepare\_unprofiled\_data()}\spxextra{MLSCAlib.Data.data\_manager.DataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.data_manager.DataManager.prepare_unprofiled_data}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{prepare\_unprofiled\_data}}}{\emph{\DUrole{n}{byte}}, \emph{\DUrole{n}{dk}}, \emph{\DUrole{n}{key\_guess}}, \emph{\DUrole{n}{leakage\_model}}, \emph{\DUrole{n}{split\_val}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{split\_rate}\DUrole{o}{=}\DUrole{default_value}{0.88}}, \emph{\DUrole{n}{min\_id}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{max\_id}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Prepares the data for each key guess in a non profiled attack.

\sphinxAtStartPar
Loads, standardizes, transforms to binary\sphinxhyphen{}categorical labels. It also reshapes the
data to allow usage on the models. The min\_id/max\_id are used in incremental learning
to find the minimum number of attack traces needed to reach GE=1 for example.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{byte}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Which byte to attack ? (between 0 and 15).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dk}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} Whether to use Domain Knowledge neurons.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{key\_guess}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} The hypotetical value of the target key byte.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{leakage\_model}} ({\hyperref[\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel}]{\sphinxcrossref{\sphinxstyleliteralemphasis{\sphinxupquote{LeakageModel}}}}}) \textendash{} The underlying LeakageModel used for label computation.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{split\_val}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to split the attack in distinct training/validation sets. If set to
False, will use the same set in validation than in tranining.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{split\_rate}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 0.8}}) \textendash{} In case split\_val is True, how much data to use for training only. The reset
being for validation.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{min\_id}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} The start index of the traces to be used.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{max\_id}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} The end index of the traces to be used.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}float{]}{]}} \textendash{} Attack traces

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} It is the labels of the attack traces, computed with the key\_guess.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} Plaintexts corresponding to the attack traces.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} List of the attack keys (na times the same key in a list).

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}float{]}{]}, \_} \textendash{} If max\_id is not None, will return all the traces until max\_id.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} It is the labels of the validation traces, computed with the key\_guess.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} Plaintexts corresponding to the validation traces.

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{set\_device() (MLSCAlib.Data.data\_manager.DataManager method)@\spxentry{set\_device()}\spxextra{MLSCAlib.Data.data\_manager.DataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.data_manager.DataManager.set_device}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_device}}}{\emph{\DUrole{n}{device}}}{}
\pysigstopsignatures
\end{fulllineitems}

\index{set\_seed() (MLSCAlib.Data.data\_manager.DataManager method)@\spxentry{set\_seed()}\spxextra{MLSCAlib.Data.data\_manager.DataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.data_manager.DataManager.set_seed}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{set\_seed}}}{\emph{\DUrole{n}{newseed}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Setter for the seed.

\end{fulllineitems}

\index{tensor\_to\_numpy() (MLSCAlib.Data.data\_manager.DataManager static method)@\spxentry{tensor\_to\_numpy()}\spxextra{MLSCAlib.Data.data\_manager.DataManager static method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.data_manager.DataManager.tensor_to_numpy}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{static\DUrole{w}{  }}}\sphinxbfcode{\sphinxupquote{tensor\_to\_numpy}}}{\emph{\DUrole{n}{array}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Turns an array of tensors to numpy arrays.

\end{fulllineitems}


\end{fulllineitems}

\index{get\_a\_free\_gpu() (in module MLSCAlib.Data.data\_manager)@\spxentry{get\_a\_free\_gpu()}\spxextra{in module MLSCAlib.Data.data\_manager}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.data_manager.get_a_free_gpu}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{MLSCAlib.Data.data\_manager.}}\sphinxbfcode{\sphinxupquote{get\_a\_free\_gpu}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Returns the available GPU torch device with the most free memory.
\begin{quote}\begin{description}
\sphinxlineitem{Returns}
\sphinxAtStartPar
A torch device able to carry the data.

\sphinxlineitem{Return type}
\sphinxAtStartPar
torch.device

\end{description}\end{quote}

\end{fulllineitems}



\paragraph{MLSCAlib.Data.custom\_manager module}
\label{\detokenize{MLSCAlib.Data:module-MLSCAlib.Data.custom_manager}}\label{\detokenize{MLSCAlib.Data:mlscalib-data-custom-manager-module}}\index{module@\spxentry{module}!MLSCAlib.Data.custom\_manager@\spxentry{MLSCAlib.Data.custom\_manager}}\index{MLSCAlib.Data.custom\_manager@\spxentry{MLSCAlib.Data.custom\_manager}!module@\spxentry{module}}\index{CustomDataManager (class in MLSCAlib.Data.custom\_manager)@\spxentry{CustomDataManager}\spxextra{class in MLSCAlib.Data.custom\_manager}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.CustomDataManager}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Data.custom\_manager.}}\sphinxbfcode{\sphinxupquote{CustomDataManager}}}{\emph{\DUrole{n}{na}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}all\textquotesingle{}}}, \emph{\DUrole{n}{ns}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}all\textquotesingle{}}}, \emph{\DUrole{n}{nt}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}all\textquotesingle{}}}, \emph{\DUrole{n}{fs}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{clean\_file\_name}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}file\_name\_attack.h5\textquotesingle{}}}, \emph{\DUrole{n}{file\_name\_profiling}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}file\_name\_attack.h5\textquotesingle{}}}, \emph{\DUrole{n}{databases\_path}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}/path/to/Databases/\textquotesingle{}}}, \emph{\DUrole{n}{has\_countermeasures}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{blind}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{force\_cpu}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{overwrite}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{imbalance\_resolution}\DUrole{o}{=}\DUrole{default_value}{ImbalanceResolution.NONE}}, \emph{\DUrole{n}{sampling\_strategy}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}auto\textquotesingle{}}}, \emph{\DUrole{n}{shuffling\_level}\DUrole{o}{=}\DUrole{default_value}{20}}, \emph{\DUrole{n}{clock\_range}\DUrole{o}{=}\DUrole{default_value}{4}}, \emph{\DUrole{n}{delay\_amplitude}\DUrole{o}{=}\DUrole{default_value}{5}}, \emph{\DUrole{n}{gaussian\_noise}\DUrole{o}{=}\DUrole{default_value}{8}}, \emph{\DUrole{n}{noisy\_file\_name}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{remove\_mask}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{DataManager}}

\sphinxAtStartPar
Custom Data Manager: class that handles countermeasures and autoencoder noise removal.

\sphinxAtStartPar
This class allows to add countermeasures to a clean dataset. It also allows to test
autoencoder\sphinxhyphen{}based noise removal as performed in Wu and Picek%
\begin{footnote}[1]\sphinxAtStartFootnote
Lichao Wu and Stjepan Picek. Denoising\sphinxhyphen{}autoencoder. \sphinxurl{https://github.com/AISyLab/Denoising-autoencoder}, 2020.
%
\end{footnote}. In this class,
the words “noise” and “countermeasures” refer to the same thing. Additionally, the class
allows to try different techniques combatting the imbalance class issues inspired
from Picek \sphinxstyleemphasis{et al.}%
\begin{footnote}[2]\sphinxAtStartFootnote
Stjepan Picek, Annelie Heuser, Alan Jovic, Shivam Bhasin, and Francesco Regazzoni. The Curse of Class Imbalance and Conflicting Metrics with Machine Learning for Side\sphinxhyphen{}channel Evaluations. \sphinxstyleemphasis{IACR Transactions on Cryptographic Hardware and Embedded Systems}, 2019(1):1\textendash{}29, August 2019. URL: \sphinxurl{https://hal.inria.fr/hal-01935318}, \sphinxhref{https://doi.org/10.13154/tches.v2019.i1.209-237}{doi:10.13154/tches.v2019.i1.209\sphinxhyphen{}237}.
%
\end{footnote}. Moreover, you can pre\sphinxhyphen{}process the traces with the following
techniques: \sphinxstyleemphasis{PCA}, \sphinxstyleemphasis{MA}, \sphinxstyleemphasis{LDA}, \sphinxstyleemphasis{QDA}, \sphinxstyleemphasis{decimation}, \sphinxstyleemphasis{append\_noise}, \sphinxstyleemphasis{SUB\sphinxhyphen{}MEAN}, \sphinxstyleemphasis{MESSERGES}, \sphinxstyleemphasis{SYNTHETIC}. Refer to
their function for detailed explanation.

\sphinxAtStartPar
The inner class working follows a \sphinxstylestrong{FSM}, with the states described in the StateMachine enum. It can only
go forward (i.e. after calling attack specific functions such as \sphinxstyleemphasis{prepare\_x\_data}, it won’t
accept adding noise or using autoencoders) for efficiency reasons. This means:
\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
You can’t add noise after having used the autoencoder or created attack data (via \sphinxstyleemphasis{prepare\_data} or \sphinxstyleemphasis{get\_res\_name}).

\item {} 
\sphinxAtStartPar
You can’t use the autoencoder after creation of attack data.

\item {} 
\sphinxAtStartPar
You don’t have to add any noise or use the autoencoders to make the attack.

\item {} 
\sphinxAtStartPar
You can’t add noise/preprocessing/autoencoder techniques after having queried \sphinxstyleemphasis{self.get\_ns}.

\end{enumerate}

\sphinxAtStartPar
This class will allways calculate the noise for all the traces on all samples. It will
store the results in a \sphinxstyleemphasis{.h5} file once it reaches the \sphinxstyleemphasis{NOISE\_FINISH\_USAGE\_IN\_ATTACK} state.
The output file\_name is composed of the original \sphinxstyleemphasis{file\_name} plus each noise added in it.

\sphinxAtStartPar
The class will use the output of the autoencoder if the function remove\_noise was called.
Otherwise, it will use the output of the function add\_noise if it was called. If none of these
functions were called, the CustomDataManager will act as a regular DataManager.
\index{\_\_init\_\_() (MLSCAlib.Data.custom\_manager.CustomDataManager method)@\spxentry{\_\_init\_\_()}\spxextra{MLSCAlib.Data.custom\_manager.CustomDataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.CustomDataManager.__init__}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{\_\_init\_\_}}}{\emph{\DUrole{n}{na}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}all\textquotesingle{}}}, \emph{\DUrole{n}{ns}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}all\textquotesingle{}}}, \emph{\DUrole{n}{nt}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}all\textquotesingle{}}}, \emph{\DUrole{n}{fs}\DUrole{o}{=}\DUrole{default_value}{0}}, \emph{\DUrole{n}{clean\_file\_name}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}file\_name\_attack.h5\textquotesingle{}}}, \emph{\DUrole{n}{file\_name\_profiling}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}file\_name\_attack.h5\textquotesingle{}}}, \emph{\DUrole{n}{databases\_path}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}/path/to/Databases/\textquotesingle{}}}, \emph{\DUrole{n}{has\_countermeasures}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{blind}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{force\_cpu}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{overwrite}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{imbalance\_resolution}\DUrole{o}{=}\DUrole{default_value}{ImbalanceResolution.NONE}}, \emph{\DUrole{n}{sampling\_strategy}\DUrole{o}{=}\DUrole{default_value}{\textquotesingle{}auto\textquotesingle{}}}, \emph{\DUrole{n}{shuffling\_level}\DUrole{o}{=}\DUrole{default_value}{20}}, \emph{\DUrole{n}{clock\_range}\DUrole{o}{=}\DUrole{default_value}{4}}, \emph{\DUrole{n}{delay\_amplitude}\DUrole{o}{=}\DUrole{default_value}{5}}, \emph{\DUrole{n}{gaussian\_noise}\DUrole{o}{=}\DUrole{default_value}{8}}, \emph{\DUrole{n}{noisy\_file\_name}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{remove\_mask}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Initializes the CustomDataManager.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{na}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} how many attack traces to use.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{ns}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} how many samples per trace to use.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{nt}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} how many profiling traces to use.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{fs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 0}}) \textendash{} First sample to use in each trace. Acts like an offset.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{clean\_file\_name}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}) \textendash{} The file name containing the traces and the metadata in .h5 format. Should be “clean”.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{seed}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 5437}}) \textendash{} The seed to use to partition and shuffle the data.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{databases\_path}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : "/path/to/Databases/"}}) \textendash{} The directory of the target file.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{has\_countermeasures}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether the underlying data was generated using counteremasures.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{blind}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to ignore the attack keys.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{force\_cpu}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} If true, won’t use the GPU’s even if available.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{imbalance\_resolution}} ({\hyperref[\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.ImbalanceResolution}]{\sphinxcrossref{\sphinxstyleliteralemphasis{\sphinxupquote{ImbalanceResolution}}}}}) \textendash{} 
\sphinxAtStartPar
In case of imbalanced data, which technique to use on the training data to counter imbalance.
\begin{itemize}
\item {} 
\sphinxAtStartPar
NONE: no technique.

\item {} 
\sphinxAtStartPar
UNDERSAMPLE: discard some samples from the majority classes.

\item {} 
\sphinxAtStartPar
SMOTE: use a SMOTE technique, which creates new rare class samples from neighboring points.

\end{itemize}

\sphinxAtStartPar
Caution: when using SMOTE, you will not be able to compute the fast GE in non profiled attacks
(or the fast GE of the training data in profiled attacks).


\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{sampling\_strategy}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{list}}\sphinxstyleliteralemphasis{\sphinxupquote{ or }}\sphinxstyleliteralemphasis{\sphinxupquote{callable}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : \textquotesingle{}auto\textquotesingle{}}}) \textendash{} 
\sphinxAtStartPar
If imbalance\_resolution is set to a downsampling strategy. Sampling information to downsample the data set.
When str, specify the class targeted by the resampling. Note the the number of samples will not be equal in each.
Possible choices are:
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{’majority’}: resample only the majority class;

\item {} 
\sphinxAtStartPar
’not minority’: resample all classes but the minority class;

\item {} 
\sphinxAtStartPar
’two minorities’: resample only two minorities classes;

\item {} 
\sphinxAtStartPar
’not majority’: resample all classes but the majority class;

\item {} 
\sphinxAtStartPar
’all’: resample all classes;

\item {} 
\sphinxAtStartPar
’auto’: equivalent to ‘not minority’.

\end{itemize}

\sphinxAtStartPar
When list, the list contains the classes targeted by the resampling.
When callable, function taking y and returns a dict. The keys correspond to the targeted classes.
The values correspond to the desired number of samples for each class.


\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{shuffling\_level}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 20}}) \textendash{} For the shuffling noise, intensity of the shuffling. Number of sample pairs to swap.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{clock\_range}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 4}}) \textendash{} For the clock jitter noise, intensity of the clock jittering.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{delay\_amplitude}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 10}}) \textendash{} For the Random Delay noise, how big the delays should be.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{gaussian\_noise}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 8}}) \textendash{} For the gaussian noise, how big the noise should be. Zero means no noise at all.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{overwrite}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to overwrite existing noisy/denoised data. As the noise addition/removal is
file specific, use this option only for test purposes.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{noisy\_file\_name}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} In case you have generated noisy traces yourself, specify the path to those traces in here.
If you specify a file, calling add\_noise() will discard your file and create a new noisy file.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{add\_noise() (MLSCAlib.Data.custom\_manager.CustomDataManager method)@\spxentry{add\_noise()}\spxextra{MLSCAlib.Data.custom\_manager.CustomDataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.CustomDataManager.add_noise}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{add\_noise}}}{\emph{\DUrole{n}{noise\_types}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Adds noise/countermeasures to the data.

\sphinxAtStartPar
This function can only be called once.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{noise\_types}} ({\hyperref[\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.NoiseTypes}]{\sphinxcrossref{\sphinxstyleliteralemphasis{\sphinxupquote{NoiseTypes}}}}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{List}}\sphinxstyleliteralemphasis{\sphinxupquote{{[}}}{\hyperref[\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.NoiseTypes}]{\sphinxcrossref{\sphinxstyleliteralemphasis{\sphinxupquote{NoiseTypes}}}}}\sphinxstyleliteralemphasis{\sphinxupquote{{]}}}) \textendash{} The types of noise to add. Can be a list of noises or just one NoiseTypes.

\end{description}\end{quote}

\end{fulllineitems}

\index{append\_noise() (MLSCAlib.Data.custom\_manager.CustomDataManager method)@\spxentry{append\_noise()}\spxextra{MLSCAlib.Data.custom\_manager.CustomDataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.CustomDataManager.append_noise}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{append\_noise}}}{\emph{\DUrole{n}{size\_ratio}\DUrole{o}{=}\DUrole{default_value}{1.0}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Appends noise to the traces, effectively making them size\_ratio longer.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{size\_ratio}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1.0}}) \textendash{} Size of the noise to be added, in comparison to the actual power measurement trace.
E.g. if set to 1.0, the number of samples will double.

\end{description}\end{quote}

\end{fulllineitems}

\index{apply\_LDA() (MLSCAlib.Data.custom\_manager.CustomDataManager method)@\spxentry{apply\_LDA()}\spxextra{MLSCAlib.Data.custom\_manager.CustomDataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.CustomDataManager.apply_LDA}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{apply\_LDA}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Applies a LinearDiscriminantAnalysis on the data. Computation is done before the attack stage begins.

\end{fulllineitems}

\index{apply\_MA() (MLSCAlib.Data.custom\_manager.CustomDataManager method)@\spxentry{apply\_MA()}\spxextra{MLSCAlib.Data.custom\_manager.CustomDataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.CustomDataManager.apply_MA}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{apply\_MA}}}{\emph{\DUrole{n}{window\_size}\DUrole{o}{=}\DUrole{default_value}{20}}, \emph{\DUrole{n}{step\_size}\DUrole{o}{=}\DUrole{default_value}{1}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Applies a Moving Average filter on the data. Computation is done before the attack stage begins.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{window\_size}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 20}}) \textendash{} Window size of the MA.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{step\_size}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1}}) \textendash{} Step size of the MA. Avoid using a step\_size \textgreater{} window\_size in order to use all sample points in the
attack.

\end{itemize}

\end{description}\end{quote}

\end{fulllineitems}

\index{apply\_PCA() (MLSCAlib.Data.custom\_manager.CustomDataManager method)@\spxentry{apply\_PCA()}\spxextra{MLSCAlib.Data.custom\_manager.CustomDataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.CustomDataManager.apply_PCA}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{apply\_PCA}}}{\emph{\DUrole{n}{nb\_components}\DUrole{o}{=}\DUrole{default_value}{225}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Applies a Principal Component Analysis on the data. Computation is done before the attack stage begins.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{nb\_components}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 225}}) \textendash{} How many principal components to retain.

\end{description}\end{quote}

\end{fulllineitems}

\index{apply\_QDA() (MLSCAlib.Data.custom\_manager.CustomDataManager method)@\spxentry{apply\_QDA()}\spxextra{MLSCAlib.Data.custom\_manager.CustomDataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.CustomDataManager.apply_QDA}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{apply\_QDA}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Applies a QuadraticDiscriminantAnalysis on the data. Computation is done before the attack stage begins.

\end{fulllineitems}

\index{apply\_autoencoder() (MLSCAlib.Data.custom\_manager.CustomDataManager method)@\spxentry{apply\_autoencoder()}\spxextra{MLSCAlib.Data.custom\_manager.CustomDataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.CustomDataManager.apply_autoencoder}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{apply\_autoencoder}}}{\emph{\DUrole{n}{epochs}\DUrole{o}{=}\DUrole{default_value}{100}}, \emph{\DUrole{n}{batch\_size}\DUrole{o}{=}\DUrole{default_value}{128}}, \emph{\DUrole{n}{verbose}\DUrole{o}{=}\DUrole{default_value}{1}}, \emph{\DUrole{n}{path\_to\_reuse\_autoencoder}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Removes the noise using an autoencoder.

\sphinxAtStartPar
If the function add\_noise() was called before, this function will remove the noise added.
If the function add\_noise() was never called, the current function will try to remove
the noise of the “clean” input database file. (which may increase the SNR by reducing
some gaussian noise).
If path\_to\_reuse\_autoencoder is not None, il will reuse an old autoencoder trained before.
You may want to use autoencoders tailored to the countermeasures in the traces you have only.
Inspired from the work done by Wu and Picek%
\begin{footnote}[3]\sphinxAtStartFootnote
Lichao Wu and Stjepan Picek. Remove some noise: on pre\sphinxhyphen{}processing of side\sphinxhyphen{}channel measurements with autoencoders. \sphinxstyleemphasis{IACR Transactions on Cryptographic Hardware and Embedded Systems}, pages 389\textendash{}415, 2020.
%
\end{footnote}.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{epochs}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 100}}) \textendash{} For how many epochs to train the autoencoder. 100 should be optimal.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{batch\_size}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 128}}) \textendash{} Batch size used for learning. 128 should be optimal (authors have tried 32, 64, 128, 256).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{verbose}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 1}}) \textendash{} Verbose used during computation. Can be between 0 and 2 (inclusive). The higher it is, the
more is going to be printed.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{path\_to\_reuse\_autoencoder}} (\sphinxstyleliteralemphasis{\sphinxupquote{str}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} If you want to reuse an autoencoder trained before, specify the path to that autoencoder here.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
The path to the denoised traces and the path to the trained/used autoencoder model.

\sphinxlineitem{Return type}
\sphinxAtStartPar
str, str

\end{description}\end{quote}

\end{fulllineitems}

\index{apply\_decimation() (MLSCAlib.Data.custom\_manager.CustomDataManager method)@\spxentry{apply\_decimation()}\spxextra{MLSCAlib.Data.custom\_manager.CustomDataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.CustomDataManager.apply_decimation}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{apply\_decimation}}}{\emph{\DUrole{n}{downsampling\_factor}\DUrole{o}{=}\DUrole{default_value}{5}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Applies downsampling on the data. Computation is done before the attack stage begins.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{downsampling\_factor}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 5}}) \textendash{} The downsampling factor.

\end{description}\end{quote}

\end{fulllineitems}

\index{apply\_mean\_removal() (MLSCAlib.Data.custom\_manager.CustomDataManager method)@\spxentry{apply\_mean\_removal()}\spxextra{MLSCAlib.Data.custom\_manager.CustomDataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.CustomDataManager.apply_mean_removal}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{apply\_mean\_removal}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Removes the mean of every trace from each trace as done in Martinasek \sphinxstyleemphasis{et al.}%
\begin{footnote}[4]\sphinxAtStartFootnote
Zdenek Martinasek, Jan Hajny, and Lukas Malina. Optimization of power analysis using neural network. In \sphinxstyleemphasis{International Conference on Smart Card Research and Advanced Applications}, 94\textendash{}107. Springer, 2013.
%
\end{footnote}.

\end{fulllineitems}

\index{apply\_messerges() (MLSCAlib.Data.custom\_manager.CustomDataManager method)@\spxentry{apply\_messerges()}\spxextra{MLSCAlib.Data.custom\_manager.CustomDataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.CustomDataManager.apply_messerges}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{apply\_messerges}}}{}{}
\pysigstopsignatures
\sphinxAtStartPar
Applies a Second Order preprocessing.

\sphinxAtStartPar
Applies a technique as described in Messerges%
\begin{footnote}[5]\sphinxAtStartFootnote
Thomas S. Messerges. Using second\sphinxhyphen{}order power analysis to attack dpa resistant software. In Çetin K. Koç and Christof Paar, editors, \sphinxstyleemphasis{Cryptographic Hardware and Embedded Systems — CHES 2000}, 238\textendash{}251. Berlin, Heidelberg, 2000. Springer Berlin Heidelberg.
%
\end{footnote}.

\end{fulllineitems}

\index{apply\_pearson() (MLSCAlib.Data.custom\_manager.CustomDataManager method)@\spxentry{apply\_pearson()}\spxextra{MLSCAlib.Data.custom\_manager.CustomDataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.CustomDataManager.apply_pearson}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{apply\_pearson}}}{\emph{\DUrole{n}{nb\_components}\DUrole{o}{=}\DUrole{default_value}{50}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Applies a Principal Component Analysis on the data. Computation is done before the attack stage begins.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{nb\_components}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 50}}) \textendash{} How many important samples to retain.

\end{description}\end{quote}

\end{fulllineitems}

\index{get\_res\_name() (MLSCAlib.Data.custom\_manager.CustomDataManager method)@\spxentry{get\_res\_name()}\spxextra{MLSCAlib.Data.custom\_manager.CustomDataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.CustomDataManager.get_res_name}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{get\_res\_name}}}{\emph{\DUrole{n}{leakage\_model}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Returns a string describing the DataManager attributes.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{leakage\_model}} ({\hyperref[\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel}]{\sphinxcrossref{\sphinxstyleliteralemphasis{\sphinxupquote{LeakageModel}}}}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} If the DataManager has not been fully initialized, it need a
leakage model in order to compute the res name. O/W,
you can ommit it.

\end{description}\end{quote}

\end{fulllineitems}

\index{prepare\_profiled\_data() (MLSCAlib.Data.custom\_manager.CustomDataManager method)@\spxentry{prepare\_profiled\_data()}\spxextra{MLSCAlib.Data.custom\_manager.CustomDataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.CustomDataManager.prepare_profiled_data}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{prepare\_profiled\_data}}}{\emph{\DUrole{n}{byte}}, \emph{\DUrole{n}{leakage\_model}}, \emph{\DUrole{n}{use\_attack\_as\_val}\DUrole{o}{=}\DUrole{default_value}{True}}, \emph{\DUrole{n}{split\_rate}\DUrole{o}{=}\DUrole{default_value}{0.95}}, \emph{\DUrole{n}{dk}\DUrole{o}{=}\DUrole{default_value}{False}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Prepares the data for profiled attacks.

\sphinxAtStartPar
This function may perform any balancing technique if requested by the
user beforehand.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{byte}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} The target byte index.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{leakage\_model}} ({\hyperref[\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel}]{\sphinxcrossref{\sphinxstyleliteralemphasis{\sphinxupquote{LeakageModel}}}}}) \textendash{} The underlying LeakageModel used for label computation.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{use\_attack\_as\_val}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} Whether to use the attack traces as validation set. If set to False, will split the profiling traces
in training/validation. If set to None, will use the attack traces as validation only if the
attack is not blind.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{split\_rate}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 0.95}}) \textendash{} In case use\_attack\_as\_val is set to False, will split the profiling traces in training/validation
traces according to split\_rate ratio.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dk}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} Whether to use Domain Knowledge neurons.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}float{]}{]}} \textendash{} Traces to use for training.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} Labels of the training traces.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}float{]}{]}} \textendash{} Traces used for validation. May be the same as the attack traces.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} Labels corresponding to the validation traces.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} Plaintexts corresponding to the validation traces.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}float{]}{]}} \textendash{} Attack traces

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} It is the labels of the attack traces, computed with the key\_guess.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} Plaintexts corresponding to the attack traces.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} List of the attack keys (na times the same key in a list).

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{prepare\_unprofiled\_data() (MLSCAlib.Data.custom\_manager.CustomDataManager method)@\spxentry{prepare\_unprofiled\_data()}\spxextra{MLSCAlib.Data.custom\_manager.CustomDataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.CustomDataManager.prepare_unprofiled_data}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{prepare\_unprofiled\_data}}}{\emph{\DUrole{n}{byte}}, \emph{\DUrole{n}{dk}}, \emph{\DUrole{n}{key\_guess}}, \emph{\DUrole{n}{leakage\_model}}, \emph{\DUrole{n}{split\_val}\DUrole{o}{=}\DUrole{default_value}{False}}, \emph{\DUrole{n}{split\_rate}\DUrole{o}{=}\DUrole{default_value}{0.8}}, \emph{\DUrole{n}{min\_id}\DUrole{o}{=}\DUrole{default_value}{None}}, \emph{\DUrole{n}{max\_id}\DUrole{o}{=}\DUrole{default_value}{None}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Prepares the data for each key guess in a non profiled attack.

\sphinxAtStartPar
Loads, standardizes, transforms to binary\sphinxhyphen{}categorical labels. It also reshapes the
data to allow usage on the models. The min\_id/max\_id are used in incremental learning
to find the minimum number of attack traces needed to reach GE=1 for example.
Additionally, this function will perform any balancing technique if requested by the
user beforehand.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{byte}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} Which byte to attack ? (between 0 and 15).

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{dk}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}) \textendash{} Whether to use Domain Knowledge neurons.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{key\_guess}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}) \textendash{} The hypotetical value of the target key byte.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{leakage\_model}} ({\hyperref[\detokenize{MLSCAlib.Ciphers:MLSCAlib.Ciphers.leakage_model.LeakageModel}]{\sphinxcrossref{\sphinxstyleliteralemphasis{\sphinxupquote{LeakageModel}}}}}) \textendash{} The underlying LeakageModel used for label computation.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{split\_val}} (\sphinxstyleliteralemphasis{\sphinxupquote{bool}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : False}}) \textendash{} Whether to split the attack in distinct training/validation sets. If set to
False, will use the same set in validation than in tranining.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{split\_rate}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 0.8}}) \textendash{} In case split\_val is True, how much data to use for training only. The reset
being for validation.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{min\_id}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} The start index of the traces to be used.

\item {} 
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{max\_id}} (\sphinxstyleliteralemphasis{\sphinxupquote{int}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : None}}) \textendash{} The end index of the traces to be used.

\end{itemize}

\sphinxlineitem{Returns}
\sphinxAtStartPar
\begin{itemize}
\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}float{]}{]}} \textendash{} Attack traces

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} It is the labels of the attack traces, computed with the key\_guess.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} Plaintexts corresponding to the attack traces.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} List of the attack keys (na times the same key in a list).

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}float{]}{]}, \_} \textendash{} If max\_id is not None, will return all the traces until max\_id.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} It is the labels of the validation traces, computed with the key\_guess.

\item {} 
\sphinxAtStartPar
\sphinxstyleemphasis{List{[}List{[}int{]}{]}} \textendash{} Plaintexts corresponding to the validation traces.

\end{itemize}


\end{description}\end{quote}

\end{fulllineitems}

\index{use\_synthetic\_traces() (MLSCAlib.Data.custom\_manager.CustomDataManager method)@\spxentry{use\_synthetic\_traces()}\spxextra{MLSCAlib.Data.custom\_manager.CustomDataManager method}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.CustomDataManager.use_synthetic_traces}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{use\_synthetic\_traces}}}{\emph{\DUrole{n}{noise}\DUrole{o}{=}\DUrole{default_value}{0.0}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Function to replace the current power traces by synthetic ones.
\begin{quote}\begin{description}
\sphinxlineitem{Parameters}
\sphinxAtStartPar
\sphinxstyleliteralstrong{\sphinxupquote{noise}} (\sphinxstyleliteralemphasis{\sphinxupquote{float}}\sphinxstyleliteralemphasis{\sphinxupquote{, }}\sphinxstyleliteralemphasis{\sphinxupquote{default : 0.0}}) \textendash{} How much noise to add in the clean synthetic data.

\end{description}\end{quote}

\end{fulllineitems}


\end{fulllineitems}

\index{ImbalanceResolution (class in MLSCAlib.Data.custom\_manager)@\spxentry{ImbalanceResolution}\spxextra{class in MLSCAlib.Data.custom\_manager}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.ImbalanceResolution}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Data.custom\_manager.}}\sphinxbfcode{\sphinxupquote{ImbalanceResolution}}}{\emph{\DUrole{n}{value}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Enum}}

\sphinxAtStartPar
Imbalance resolution techniques.

\sphinxAtStartPar
For help, see: \sphinxurl{https://imbalanced-learn.org/stable/references/index.html} .
\index{NCR\_SMOTE (MLSCAlib.Data.custom\_manager.ImbalanceResolution attribute)@\spxentry{NCR\_SMOTE}\spxextra{MLSCAlib.Data.custom\_manager.ImbalanceResolution attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.ImbalanceResolution.NCR_SMOTE}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{NCR\_SMOTE}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }5}}}
\pysigstopsignatures
\sphinxAtStartPar
Applies first a \sphinxstyleemphasis{NEIGHBOURHOOD\_CLEANING\_RULE} and then \sphinxstyleemphasis{SMOTE}.

\end{fulllineitems}

\index{NEIGHBOURHOOD\_CLEANING\_RULE (MLSCAlib.Data.custom\_manager.ImbalanceResolution attribute)@\spxentry{NEIGHBOURHOOD\_CLEANING\_RULE}\spxextra{MLSCAlib.Data.custom\_manager.ImbalanceResolution attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.ImbalanceResolution.NEIGHBOURHOOD_CLEANING_RULE}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{NEIGHBOURHOOD\_CLEANING\_RULE}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }3}}}
\pysigstopsignatures
\end{fulllineitems}

\index{NONE (MLSCAlib.Data.custom\_manager.ImbalanceResolution attribute)@\spxentry{NONE}\spxextra{MLSCAlib.Data.custom\_manager.ImbalanceResolution attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.ImbalanceResolution.NONE}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{NONE}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }0}}}
\pysigstopsignatures
\end{fulllineitems}

\index{ONESIDED\_SELECTION (MLSCAlib.Data.custom\_manager.ImbalanceResolution attribute)@\spxentry{ONESIDED\_SELECTION}\spxextra{MLSCAlib.Data.custom\_manager.ImbalanceResolution attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.ImbalanceResolution.ONESIDED_SELECTION}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{ONESIDED\_SELECTION}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }2}}}
\pysigstopsignatures
\end{fulllineitems}

\index{OSS\_SMOTE (MLSCAlib.Data.custom\_manager.ImbalanceResolution attribute)@\spxentry{OSS\_SMOTE}\spxextra{MLSCAlib.Data.custom\_manager.ImbalanceResolution attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.ImbalanceResolution.OSS_SMOTE}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{OSS\_SMOTE}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }4}}}
\pysigstopsignatures
\sphinxAtStartPar
Applies first a \sphinxstyleemphasis{ONESIDED\_SELECTION} and then \sphinxstyleemphasis{SMOTE}.

\end{fulllineitems}

\index{RANDOM\_UNDERSAMPLER (MLSCAlib.Data.custom\_manager.ImbalanceResolution attribute)@\spxentry{RANDOM\_UNDERSAMPLER}\spxextra{MLSCAlib.Data.custom\_manager.ImbalanceResolution attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.ImbalanceResolution.RANDOM_UNDERSAMPLER}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{RANDOM\_UNDERSAMPLER}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }3.5}}}
\pysigstopsignatures
\end{fulllineitems}

\index{SMOTE (MLSCAlib.Data.custom\_manager.ImbalanceResolution attribute)@\spxentry{SMOTE}\spxextra{MLSCAlib.Data.custom\_manager.ImbalanceResolution attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.ImbalanceResolution.SMOTE}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{SMOTE}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }1}}}
\pysigstopsignatures
\end{fulllineitems}

\index{SMOTE\_TOMEK (MLSCAlib.Data.custom\_manager.ImbalanceResolution attribute)@\spxentry{SMOTE\_TOMEK}\spxextra{MLSCAlib.Data.custom\_manager.ImbalanceResolution attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.ImbalanceResolution.SMOTE_TOMEK}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{SMOTE\_TOMEK}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }6}}}
\pysigstopsignatures
\sphinxAtStartPar
Applies first \sphinxstyleemphasis{SMOTE} and then \sphinxstyleemphasis{TOMEK}.

\end{fulllineitems}


\end{fulllineitems}

\index{NoiseTypes (class in MLSCAlib.Data.custom\_manager)@\spxentry{NoiseTypes}\spxextra{class in MLSCAlib.Data.custom\_manager}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.NoiseTypes}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxbfcode{\sphinxupquote{class\DUrole{w}{  }}}\sphinxcode{\sphinxupquote{MLSCAlib.Data.custom\_manager.}}\sphinxbfcode{\sphinxupquote{NoiseTypes}}}{\emph{\DUrole{n}{value}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Bases: \sphinxcode{\sphinxupquote{Enum}}

\sphinxAtStartPar
Available noise \& countermeasures types.
\index{CLOCK\_JITTER (MLSCAlib.Data.custom\_manager.NoiseTypes attribute)@\spxentry{CLOCK\_JITTER}\spxextra{MLSCAlib.Data.custom\_manager.NoiseTypes attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.NoiseTypes.CLOCK_JITTER}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{CLOCK\_JITTER}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }2}}}
\pysigstopsignatures
\end{fulllineitems}

\index{GAUSSIAN (MLSCAlib.Data.custom\_manager.NoiseTypes attribute)@\spxentry{GAUSSIAN}\spxextra{MLSCAlib.Data.custom\_manager.NoiseTypes attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.NoiseTypes.GAUSSIAN}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{GAUSSIAN}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }0}}}
\pysigstopsignatures
\end{fulllineitems}

\index{MA (MLSCAlib.Data.custom\_manager.NoiseTypes attribute)@\spxentry{MA}\spxextra{MLSCAlib.Data.custom\_manager.NoiseTypes attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.NoiseTypes.MA}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{MA}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }4}}}
\pysigstopsignatures
\end{fulllineitems}

\index{RANDOM\_DELAY (MLSCAlib.Data.custom\_manager.NoiseTypes attribute)@\spxentry{RANDOM\_DELAY}\spxextra{MLSCAlib.Data.custom\_manager.NoiseTypes attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.NoiseTypes.RANDOM_DELAY}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{RANDOM\_DELAY}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }1}}}
\pysigstopsignatures
\end{fulllineitems}

\index{SHUFFLING (MLSCAlib.Data.custom\_manager.NoiseTypes attribute)@\spxentry{SHUFFLING}\spxextra{MLSCAlib.Data.custom\_manager.NoiseTypes attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.NoiseTypes.SHUFFLING}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{SHUFFLING}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }3}}}
\pysigstopsignatures
\end{fulllineitems}

\index{SHUFFLING\_VARIANT (MLSCAlib.Data.custom\_manager.NoiseTypes attribute)@\spxentry{SHUFFLING\_VARIANT}\spxextra{MLSCAlib.Data.custom\_manager.NoiseTypes attribute}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib.Data:MLSCAlib.Data.custom_manager.NoiseTypes.SHUFFLING_VARIANT}}
\pysigstartsignatures
\pysigline{\sphinxbfcode{\sphinxupquote{SHUFFLING\_VARIANT}}\sphinxbfcode{\sphinxupquote{\DUrole{w}{  }\DUrole{p}{=}\DUrole{w}{  }3.5}}}
\pysigstopsignatures
\end{fulllineitems}


\end{fulllineitems}



\subsection{Submodules}
\label{\detokenize{MLSCAlib:submodules}}

\subsection{MLSCAlib.main module}
\label{\detokenize{MLSCAlib:module-MLSCAlib.main}}\label{\detokenize{MLSCAlib:mlscalib-main-module}}\index{module@\spxentry{module}!MLSCAlib.main@\spxentry{MLSCAlib.main}}\index{MLSCAlib.main@\spxentry{MLSCAlib.main}!module@\spxentry{module}}
\sphinxAtStartPar
This script runs a ML attack on AES.
\index{script\_parser() (in module MLSCAlib.main)@\spxentry{script\_parser()}\spxextra{in module MLSCAlib.main}}

\begin{fulllineitems}
\phantomsection\label{\detokenize{MLSCAlib:MLSCAlib.main.script_parser}}
\pysigstartsignatures
\pysiglinewithargsret{\sphinxcode{\sphinxupquote{MLSCAlib.main.}}\sphinxbfcode{\sphinxupquote{script\_parser}}}{\emph{\DUrole{n}{user\_input}}}{}
\pysigstopsignatures
\sphinxAtStartPar
Parses the use input arguments and create attack classes.

\end{fulllineitems}



\chapter{Indices and tables}
\label{\detokenize{index:indices-and-tables}}\begin{itemize}
\item {} 
\sphinxAtStartPar
\DUrole{xref,std,std-ref}{genindex}

\item {} 
\sphinxAtStartPar
\DUrole{xref,std,std-ref}{modindex}

\item {} 
\sphinxAtStartPar
\DUrole{xref,std,std-ref}{search}

\end{itemize}


\renewcommand{\indexname}{Python Module Index}
\begin{sphinxtheindex}
\let\bigletter\sphinxstyleindexlettergroup
\bigletter{m}
\item\relax\sphinxstyleindexentry{MLSCAlib.Architectures.autoencoders}\sphinxstyleindexpageref{MLSCAlib.Architectures:\detokenize{module-MLSCAlib.Architectures.autoencoders}}
\item\relax\sphinxstyleindexentry{MLSCAlib.Architectures.torch\_models}\sphinxstyleindexpageref{MLSCAlib.Architectures:\detokenize{module-MLSCAlib.Architectures.torch_models}}
\item\relax\sphinxstyleindexentry{MLSCAlib.Attacks.attack}\sphinxstyleindexpageref{MLSCAlib.Attacks:\detokenize{module-MLSCAlib.Attacks.attack}}
\item\relax\sphinxstyleindexentry{MLSCAlib.Attacks.profiled}\sphinxstyleindexpageref{MLSCAlib.Attacks:\detokenize{module-MLSCAlib.Attacks.profiled}}
\item\relax\sphinxstyleindexentry{MLSCAlib.Attacks.unprofiled}\sphinxstyleindexpageref{MLSCAlib.Attacks:\detokenize{module-MLSCAlib.Attacks.unprofiled}}
\item\relax\sphinxstyleindexentry{MLSCAlib.Ciphers.AES\_leakage}\sphinxstyleindexpageref{MLSCAlib.Ciphers:\detokenize{module-MLSCAlib.Ciphers.AES_leakage}}
\item\relax\sphinxstyleindexentry{MLSCAlib.Ciphers.leakage\_model}\sphinxstyleindexpageref{MLSCAlib.Ciphers:\detokenize{module-MLSCAlib.Ciphers.leakage_model}}
\item\relax\sphinxstyleindexentry{MLSCAlib.Data.chipwhisperer\_converter}\sphinxstyleindexpageref{MLSCAlib.Data:\detokenize{module-MLSCAlib.Data.chipwhisperer_converter}}
\item\relax\sphinxstyleindexentry{MLSCAlib.Data.custom\_manager}\sphinxstyleindexpageref{MLSCAlib.Data:\detokenize{module-MLSCAlib.Data.custom_manager}}
\item\relax\sphinxstyleindexentry{MLSCAlib.Data.data\_manager}\sphinxstyleindexpageref{MLSCAlib.Data:\detokenize{module-MLSCAlib.Data.data_manager}}
\item\relax\sphinxstyleindexentry{MLSCAlib.main}\sphinxstyleindexpageref{MLSCAlib:\detokenize{module-MLSCAlib.main}}
\end{sphinxtheindex}

\renewcommand{\indexname}{Index}
\printindex
\end{document}